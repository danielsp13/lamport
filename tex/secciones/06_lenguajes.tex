\chapter{\textbf{Fundamentos de Lenguajes y Modelos de Computación}}
Este capítulo profundiza en los fundamentos teóricos de los lenguajes y gramáticas, cruciales para el análisis y construcción de lenguajes de programación, los cuales constituyen la piedra angular de este proyecto. Se explorarán también conceptos básicos de modelos de computación, que proporcionan un marco teórico para entender el procesamiento de información y la ejecución de tareas en sistemas computacionales. Estos modelos son esenciales para comprender la implementación e interpretación de lenguajes en entornos computacionales, incluyendo el papel de intérpretes y compiladores.

Finalmente, se dedica una sección a los intérpretes, destacando su relevancia en la ejecución de programas y en la interpretación de lenguajes en un contexto más amplio. Se examinará cómo estos sistemas procesan y ejecutan lenguajes definidos por gramáticas de variados niveles de complejidad.

\section{Alfabetos y palabras}\label{section:MCAlphabet}
El alfabeto, constituido por un conjunto de símbolos básicos, es el punto de inicio para la formación de cualquier lenguaje. La combinación de estos símbolos da lugar a palabras o cadenas, que son los pilares para estructuras lingüísticas más complejas. Las operaciones sobre estas cadenas, como la concatenación y la sustitución, son clave para comprender la construcción y manipulación de los lenguajes.

Formalmente, un \textbf{alfabeto} es un conjunto finito $A$ cuyos elementos se denominan \textbf{símbolos} o \textbf{letras}. En lo que respecta a la notación, se optará por utilizar las primeras letras del abecedario para sendos conceptos, empleando las mayúsculas para los alfabetos y las minúsculas para los símbolos, además de considerar notación subíndice si fuese necesario. 

Por otro lado, una \textbf{palabra} o \textbf{cadena} sobre el alfabeto $A$ es una sucesión finita de elementos de $A$, esto es:

\begin{align*}
    u = a_1 \ldots a_n
\end{align*}

donde $a_i \in A, \forall i \in \mathbb{N}$. Por ejemplo, considerando el alfabeto $A = \left\lbrace a,b,0,1 \right\rbrace$, entonces $u = 001abb1$ es una palabra sobre ese alfabeto. Al conjunto de todas las palabras sobre un alfabeto $A$ se denomina $A^*$. Para las palabras, se convendrá utilizar las últimas letras del abecedario, a saber, $u,v,w,x,y,z$, o letras griegas minúsculas.

Si $u \in A^*$, se entiende por \textbf{longitud} de la palabra $u$ al número de símbolos de $A$ que contiene. La notación empleada para indicar la longitud será $|u|$. Si $u = a_1\ldots a_n$, entonces $|u| = n$. Existe un tipo especial de palabra y es la denominada como \textbf{palabra vacía}, una palabra cuya longitud es 0, y se nombra utilizando el símbolo $\epsilon$. Al conjunto de palabras sobre el alfabeto $A$ donde se elimina la palabra vacía $\epsilon$, se denota por $A^+$.

Habiendo introducido los elementos más básicos, lo que sigue es definir operaciones para su manipulación. Si $u,v \in A^*, u=a_1 \ldots v=b_1\ldots b_m$, se entiende por \textbf{concatenación} de $u,v$ a la cadena $uv$ dada por:

\begin{align*}
    uv = a_1 \ldots a_n b_1 \ldots b_m
\end{align*}

\noindent
Esta operación verifica las siguientes propiedades:
\begin{enumerate}
    \item $|uv| = |u| + |v|, \forall u,v \in A^*$
    \item  Asociatividad: $u(vw) = (uv)w, \forall u,v,w \in A^*$
    \item Elemento neutro: $u\epsilon = \epsilon u = u, \forall u \in A^*$
\end{enumerate}

Finalmente, la construcción de palabras se puede realizar mediante un proceso iterativo. La \textbf{iteración} $n$-ésima de una cadena $u = a_1 \ldots a_n$, referida como $u^n$, indica la concatenación de la palabra $u$ consigo misma $n$ veces. Por otro lado, se denomina como \textbf{cadena inversa} a la palabra $u^{-1}$, resultante de invertir la escritura de sus símbolos, esto es: $u^{-1} = a_n \ldots a_1$.

\section{Lenguajes}\label{section:languages}
Manejar con un conjunto tan grande como puede ser el de todas las palabras sobre un determinado alfabeto $A$ es poco menos que realista, hablando en el sentido computacional \footnote{En particular, $A^*$ es \textbf{siempre} numerable.}. Un \textbf{lenguaje} sobre el alfabeto $A$ es un subconjunto del conjunto de las cadenas sobre $A$, es decir: $L \subseteq A^*$. Se utilizarán las letras $L,M,N$ para denotar lenguajes, además de subíndices si es oportuno. En otras palabras, los lenguajes incluyen reglas específicas en la construcción de palabras concretas sobre un alfabeto $A$. Aquí se presentan algunos ejemplos:

\begin{itemize}
    \item $L_1 = \left\lbrace 0^i 1^i : i = 0,1,2,\ldots \right\rbrace$. Este lenguaje denota una sucesión de ceros seguida de una sucesión de 1 de la misma longitud.

    \item $L_2 = \left\lbrace uu^{-1} : u \in A^* \right\rbrace $. Este lenguaje denota la concatenación de cualquier palabra sobre el alfabeto $A$ concatenada con su inverso, lo que se conoce como \textit{palíndromo}.
\end{itemize}

Sobre los lenguajes también se pueden realizar operaciones, como las de \textbf{intersección} y \textbf{unión} clásicas de los conjuntos. Además, también se puede realizar la \textbf{concatenación} de una forma similar a la que se ha definido para las palabras, así como el lenguaje \textbf{inverso}, o la \textbf{iteración}. Sobre esta última operación se define otra nueva, denominada \textbf{clausura de Kleene} y definida como:

\begin{align*}
    L^* &= \bigcup_{i \geq 0} L^i \\
    L^+ &= \bigcup_{i \geq 1} L^i
\end{align*}

\noindent
considerando que $L$ es un lenguaje sobre el alfabeto $A$.

\section{Gramática}\label{section:gramatica}
\noindent
Una \textbf{gramática generativa} o simplemente \textbf{gramática} es una cuádrupla:

\begin{align*}
    \mathcal{G} = (V,T,P,S)
\end{align*}

\noindent
en la que:

\begin{itemize}
    \item $V$ es un alfabeto de \textbf{variables} o \textbf{símbolos no terminales}. Sus elementos convendrá representarlos con letras mayúsculas.
    \item $T$ es un alfabeto de \textbf{símbolos terminales}. Sus elementos convendrá representarlos con letras minúsculas.
    \item $P$ es un conjunto finito de pares $(\alpha,\beta)$, denomindaos \textbf{reglas de producción}, donde $\alpha,\beta \in (V \cup T)^*$ y $\alpha$ contiene al menos un símbolo de $V$. Al par anteriormente mencionado convendrá representarlos por $\alpha \rightarrow \beta$.
    \item $S$ es un elemento de $V$, llamado \textbf{símbolo de partida}.
\end{itemize}

La idea es que una gramática sirve para determinar un lenguaje. Las palabras son las de $T^*$ que se obtienen a partir del símbolo inicial $S$ efectuando \textit{pasos de derivación}. Sea $\mathcal{G} = (V,T,P,S)$ y $(\alpha,\beta)\in (V \cup T)^*$. Se dice que $\beta$ es \textbf{derivable} a partir de $\alpha$ \textbf{en un paso} (escrito como $\alpha \implies \beta$) si y sólo si existe una producción $\gamma \rightarrow \phi$ tal que:

\begin{enumerate}
    \item $\alpha$ contiene a $\gamma$ como subcadena.
    \item $\beta$ se obtiene sustituyendo $\gamma$ por $\phi$ en $\alpha$.
\end{enumerate}

La definición anterior comprende un \textbf{paso de derivación}. No obstante, se puede decir que $\beta$ es \textbf{derivable} de $\alpha$ (escrito como $\alpha \overset{*}{\implies} \beta$) si y sólo si existe una sucesión de palabras $\gamma_1,\ldots,\gamma_n, (n \geq 1)$ tales que:

\begin{align*}
    \alpha = \gamma_1 \implies \gamma_2 \implies \ldots \implies \gamma_n = \beta
\end{align*}

\subsection{Lenguaje generado}\label{subsection:gramaticalanguage}
Se dice que $L$ es el \textbf{lenguaje generado} por una gramática $\mathcal{G} = (V,T,P,S)$ al conjunto de palabras formadas por símbolos terminales que son derivables partiendo del símbolo inicial $S$. Formalmente:

\begin{align*}
    L(\mathcal{G}) = \lbrace u \in T^* : S \overset{*}{\implies} u \rbrace
\end{align*}

\section{Jerarquía de Chomsky}\label{section:chomsky}
La Jerarquía de Chomsky, propuesta por Noam Chomsky en 1956, es un marco teórico que clasifica los lenguajes formales en distintos niveles según su complejidad gramatical. Esta jerarquía se divide en cuatro categorías: gramáticas regulares, libres de contexto, sensibles al contexto y recursivamente enumerables. Cada nivel representa un grado de complejidad en la generación y el procesamiento de lenguajes, siendo fundamental para entender la teoría de la computación y el desarrollo de lenguajes de programación. La jerarquía de Chomsky queda determinada como sigue:

\begin{itemize}
    \item \textbf{Tipo 0}: Cualquier gramática sin restricciones. Da lugar a \textbf{lenguajes recursivamente enumerables}.
    \item \textbf{Tipo 1}: Todas las producciones tienen la forma:
    \begin{align*}
        \alpha_1 A \alpha_2 \rightarrow \alpha_1 \beta \alpha_2
    \end{align*}
    donde $\alpha_1,\alpha_2,\beta \in (V \cup T)^*, A \in V, \beta \neq \epsilon$, exceptuando la regla $S \rightarrow \epsilon$, en cuyo caso $S$ no aparece a la derecha de las reglas. Esto da lugar a \textbf{lenguajes dependientes del contexto}.
    \item \textbf{Tipo 2}: Cualquier producción tiene la forma:
    \begin{align*}
        A \rightarrow \alpha
    \end{align*}
    donde $A \in V, \alpha \in (V \cup T)^*$. Esto da lugar a \textbf{lenguajes independientes del contexto}.
    \item \textbf{Tipo 3}: Toda regla tiene la forma:
    \begin{align*}
        A \rightarrow uB \hspace{0.2cm} \text{ó} \hspace{0.2cm} A \rightarrow u
    \end{align*}
    donde $u \in T^*; A,B \in V$. Da lugar a \textbf{lenguajes regulares}.
\end{itemize}

La clase o familia de lenguajes de los tipos anteriormente mencionados se denota por $\mathcal{L}_i, i = 0,1,2,3$. Además, se verifica la siguiente cadena de inclusiones:

\begin{align*}
    \mathcal{L}_3 \subseteq \mathcal{L}_2 \subseteq \mathcal{L}_1 \subseteq \mathcal{L}_0
\end{align*}

Para este proyecto es esencial considerar los lenguajes independientes de contexto, que son los que constituyen lenguajes de progamación. También los lenguajes regulares, útiles para el reconocimiento de cadenas.

\section{Expresiones regulares}\label{section:expr}
Las expresiones regulares son una herramienta teórica fundamental en el estudio de los lenguajes formales, específicamente los lenguajes regulares. Se utilizan para describir de manera sintética y precisa los patrones y estructuras que conforman estos lenguajes. A través de una serie de símbolos y operadores, las expresiones regulares permiten representar conjuntos infinitos de cadenas y facilitan el análisis y clasificación de estos lenguajes en la teoría de la computación. Su estudio es esencial para comprender cómo se pueden definir y reconocer los lenguajes regulares, que son la base de modelos más complejos en la informática y la lingüística teórica.

Si $A$ es un alfabeto, una \textbf{expresión regular} sobre ese alfabeto se define de la siguiente forma:

\begin{itemize}
    \item $\emptyset$ es una expresión regular que denota el lenguaje vacío.
    \item $\epsilon$ es una expresión regular que denota el lenguaje $\lbrace \epsilon \rbrace$.
    \item Si $a \in A$, \textbf{a} es una expresión regular que denota el lenguaje $\lbrace a \rbrace$.
    \item Si \textbf{r,s} son expresiones regulares que denotan los lenguajes $R,S$ respectivamente, se definen las operaciones:
    \begin{itemize}
        \item \textbf{Unión}: \textbf{(r + s)} es una expresión regular que denota el lenguaje $R \cup S$.
        \item \textbf{Concatenación}: \textbf{rs} es una expresión regular que denota el lenguaje $RS$.
        \item \textbf{Clausura}: \textbf{r$^*$} es una expresión regular que denota el lenguaje $R^*$.
    \end{itemize}
\end{itemize}

Sean $r,r_1,r_2$ expresiones regulares. Algunas de las propiedades más importantes de las expresiones regulares son las siguientes:
\vspace{0.5cm}
\newline
\begin{tabular}{ll}
    $r_1 + r_2 = r_2 + r_1$ & $r_1(r_2+r_3) = r_1r_2 + r_1r_3$ \\
    $r_1 + (r_2 + r_3) = (r_1 + r_2) + r_3$ & $(r_1+r_2)r_3 = r_1r_3 + r_2r_3$ \\
    $r_1(r_2r_3) = (r_1r_2)r_3$ & $r^+ + \epsilon = r^*$ \\
    $r\epsilon = r$ & $r^* + \epsilon = r^*$ \\
    $r\emptyset = \emptyset$ & $(r+\epsilon)^* = r^*$ \\
    $r+\emptyset = r$ & $(r+\epsilon)^+ = r^*$ \\
    $\epsilon^* = \epsilon$ & $(r_1^*+r_2^*)^* = (r_1+r_2)^*$ \\
\end{tabular}
\vspace{0.5cm}

\noindent
Algunos ejemplos de expresiones regulares son los siguientes:
\begin{itemize}
    \item $(0+1)^*$: Representa una secuencia de ceros y unos en cualquier combinación, incluyendo la palabra vacía, denotada como $\epsilon$. Ejemplos de palabras aceptadas por esta expresión incluyen $011101$, $1$, $000$, y $\epsilon$.
    \item $a(bb)^*c+d$: Esta expresión puede interpretarse de dos maneras principales. Primero, como una secuencia que comienza con un símbolo $a$, seguido de cualquier número (incluido cero) de pares de $b$, y terminando con un $c$. Alternativamente, puede ser simplemente la letra $d$. Ejemplos de palabras aceptadas incluirían $abbc$, $ac$, $abbbbc$, y $d$.
\end{itemize}



\section{Computación de lenguajes. Autómatas}\label{section:automat}
Esta sección explora el papel fundamental de los autómatas en la computación de lenguajes. Los autómatas finitos, que son esenciales en el reconocimiento de lenguajes regulares, actúan como modelos simplificados de computación. Estos se representan mediante grafos conocidos como diagramas de transición de estados, que ilustran cómo un sistema cambia de un estado a otro en respuesta a entradas específicas.

Más allá de los autómatas finitos, se introducen también los autómatas con pila, que son cruciales para el reconocimiento de lenguajes independientes del contexto. Estos autómatas se caracterizan por su capacidad de almacenar una cantidad de información adicional gracias a su ``pila'', lo que les permite procesar estructuras más complejas que las que pueden manejar los autómatas finitos. La habilidad de los autómatas con pila para manejar gramáticas libres de contexto los hace particularmente importantes en el análisis sintáctico de lenguajes de programación y en la comprensión de estructuras más complejas en la informática teórica.

\subsection{Autómatas finitos}\label{subsection:AF}
La función de los autómatas finitos es la de \textit{reconocer} un determinado patrón a partir de una palabra de entrada. Pueden ser de dos tipos:

\begin{itemize}
    \item \textbf{Autómatas Finitos no Deterministas (AFND)}. Estos autómatas no presentan limitaciones en las etiquetas de sus transiciones. Es posible que un mismo símbolo etiquete múltiples transiciones originadas en un estado idéntico, y se permite el uso de $\epsilon$ como etiqueta.
    \item \textbf{Autómatas Finitos Deterministas (AFD)}. Cada estado en estos autómatas, para cada símbolo del alfabeto de entrada, cuenta con una única transición correspondiente a ese símbolo que se origina en dicho estado.
\end{itemize}

\noindent
Formalmente, se define un autómata se define como una quíntupla:

\begin{align*}
    M = (Q,A,\delta,q_0,F)
\end{align*}

\noindent
donde:
\begin{itemize}
    \item $Q$ es un conjunto finito llamado \textbf{conjunto de estados}.
    \item $A$ es un alfabeto llamado \textbf{alfabeto de entrada}.
    \item $\delta$ es una aplicación llamada \textbf{función de transición}.
    \item $q_0$ es un elemento de $Q$ llamado \textbf{estado inicial}.
    \item $F$ es un subconjunto de $Q$, llamado \textbf{conjunto de estados finales}.
\end{itemize}

La diferencia entre un AFND con transiciones nulas y un AFD es en la definición de la función de transición.

Una propiedad interesante en el estudio de los autómatas y los lenguajes formales es la equivalencia entre autómatas finitos no deterministas con transiciones nulas (AFND) y autómatas finitos deterministas (AFD). Específicamente, un lenguaje $L$ puede ser aceptado por un AFND con transiciones nulas si y sólo si existe un AFD que también acepta $L$. El lenguaje aceptado por un autómata $M$ se denota como $L(M)$. Profundizando en esta relación, una característica notable es que un lenguaje $L$ es aceptado por un AFD si y sólo si puede ser descrito mediante una expresión regular. Finalmente, cabe destacar que todo AFND con transiciones nulas puede ser convertido en un AFD equivalente, lo que demuestra una correspondencia fundamental entre estos dos tipos de autómatas en la teoría de lenguajes formales. Hay varios algoritmos de conversión, algunos de ellos mencionados en \cite{aho1990compiladores} (sección 3.7).

\subsubsection{Generación de analizadores léxicos}\label{subsubsection:}
La generación de analizadores léxicos es un imprescindible en el análisis de lenguajes de programación, donde las expresiones regulares y los autómatas juegan un papel importantísimo. Estos analizadores, diseñados para reconocer patrones léxicos en el código fuente, son a menudo construidos utilizando herramientas como Flex, que convierte expresiones regulares en autómatas finitos. Flex simplifica este proceso al permitir la definición de patrones léxicos a través de expresiones regulares, que luego son automáticamente transformadas en un AFND y posteriormente en un AFD para el análisis eficiente del texto de entrada. Este enfoque aprovecha la teoría de autómatas y las propiedades de las expresiones regulares para crear sistemas capaces de descomponer y entender la estructura léxica de los lenguajes de programación.

\subsection{Autómatas con pila}\label{subsection:automatPila}
En la sección ~\ref{section:chomsky} se ha hablado acerca de las gramáticas independientes del contexto. Estas gramáticas, que generan lenguajes más complejos que los lenguajes regulares, requieren un mecanismo de análisis más avanzado para su procesamiento. Aquí es donde entran en juego los autómatas con pila, una forma extendida de autómatas que son capaces de manejar esta complejidad adicional.

Los autómatas con pila son una clase de autómatas que, a diferencia de los autómatas finitos, cuentan con una memoria adicional en forma de una pila. Esta característica les permite no solo procesar la entrada actual, sino también almacenar y recuperar información, lo que es esencial para manejar dependencias a largo plazo y estructuras anidadas típicas de los lenguajes independientes del contexto. Por lo tanto, son herramientas fundamentales para el análisis sintáctico en compiladores y para el entendimiento profundo de la computación y procesamiento de lenguajes más complejos.



\noindent
Formalmente, un \textbf{Autómata con Pila} es una séptupla:

\begin{align*}
    M = (Q,A,B,\delta,q_0,Z_0,F)
\end{align*}

\noindent
donde:
\begin{itemize}
    \item $Q$ es un conjunto finito llamado \textbf{conjunto de estados}.
    \item $A$ es un alfabeto llamado \textbf{alfabeto de entrada}.
    \item $B$ es un alfabeto llamado \textbf{alfabeto de pila}.
    \item $\delta$ es una aplicación llamada \textbf{función de transición}.
    \item $q_0$ es un elemento de $Q$ llamado \textbf{estado inicial}.
    \item $Z_0 \in B$ es el \textbf{símbolo inicial de pila}
    \item $F$ es un subconjunto de $Q$, llamado \textbf{conjunto de estados finales}.
\end{itemize}

También hay versiones deterministas y no deterministas, donde la diferencia reside en las condiciones a imponer sobre la función de transición. Un lenguaje independiente del contexto se dice que es \textbf{determinista} si y sólo si es aceptado por un autómata con pila determinista por el \textit{criterio de estados finales}. Este criterio implica que un autómata con pila determinista acepta una cadena de entrada si, y solo si, al finalizar el procesamiento de la cadena, el autómata llega a un estado final y la pila está vacía. En otras palabras, la aceptación de una cadena no solo depende de alcanzar un estado final, sino también de que la pila se haya vaciado completamente al final del procesamiento. Esto asegura que el autómata no solo reconoce la secuencia de símbolos de la cadena de entrada, sino que también cumple con las restricciones adicionales impuestas por la estructura de la pila.

\subsubsection{Generación de analizadores sintácticos}\label{subsubsection:analizadoresyntax}
La utilidad de los autómatas con pila se extiende más allá de la teoría y encuentra una aplicación práctica significativa en la generación de analizadores sintácticos. El proceso de análisis sintáctico implica reconocer patrones y estructuras sintácticas más complejas, una tarea para la cual los autómatas con pila están especialmente equipados. Gracias a su capacidad de almacenar y manejar información contextual en la pila, pueden eficientemente analizar gramáticas independientes del contexto, que son típicas en la mayoría de los lenguajes de programación modernos.

Herramientas como Yacc (Yet Another Compiler-Compiler) y su sucesor Bison, utilizan la teoría de los autómatas con pila para generar analizadores sintácticos. Estas herramientas toman una especificación de gramática y producen un analizador que puede descomponer y analizar estructuras lingüísticas complejas, siguiendo las reglas definidas en la gramática. Al igual que con los analizadores léxicos, el uso de autómatas con pila simplifica enormemente el proceso de desarrollo de software, permitiendo a los programadores y desarrolladores de lenguajes centrarse en la definición de reglas gramaticales, mientras la herramienta maneja los detalles del análisis sintáctico.

\section{Herramientas de procesamiento de lenguajes. Compiladores e intérpretes}\label{section:compiladores}
Lo acontecido en secciones anteriores en este capítulo ofrecen un marco teórico más que suficiente para el desarrollo de los siguientes capítulos que se centran en la parte práctica del proyecto. En esta última sección se hablará de herramientas prácticas para el procesamiento de lenguajes: los \textit{compiladores} e \textit{intérpretes}. Estas herramientas tienen como objetivo convertir el código fuente escrito en un lenguaje de programación a un formático que la máquina pueda ejecutar o interpretar directamente.

Un \textbf{compilador} es un programa que traduce código fuente escrito en lenguaje de alto nivel a lenguaje máquina o a un código intermedio. El proceso de compilación consta de varias fases:

\begin{enumerate}
    \item \textbf{Análisis léxico}: 
        \begin{itemize}
            \item El compilador lee el código fuente y lo descompone en tokens.
            \item Los tokens pueden ser identificadores, palabras clave, constantes, operadores, etc.
            \item Se simplifica y estructura el código fuente para las fases posteriores.
        \end{itemize}

    \item \textbf{Análisis sintáctico}:
        \begin{itemize}
            \item Organiza los tokens en un árbol sintáctico que representa la estructura gramatical.
            \item Verifica que la secuencia de tokens siga las reglas gramaticales del lenguaje.
            \item Identifica errores de sintaxis como paréntesis faltantes o errores en construcciones de bucles.
        \end{itemize}

    \item \textbf{Análisis semántico}:
        \begin{itemize}
            \item Verifica la corrección semántica del código, asegurando que los elementos del programa tengan sentido en su contexto.
            \item Incluye la verificación de tipos de datos y la coherencia en el uso de variables y funciones.
            \item Detecta errores como asignaciones de tipos de datos incorrectos o llamadas incorrectas a funciones.
        \end{itemize}

    \item \textbf{Generación de código intermedio}:
        \begin{itemize}
            \item Transforma el árbol sintáctico en una representación intermedia.
            \item Esta representación es independiente del lenguaje de programación y del hardware.
            \item Facilita la optimización del código y prepara la generación del código máquina.
        \end{itemize}

    \item \textbf{Optimización de código}:
        \begin{itemize}
            \item Mejora la representación intermedia para aumentar la eficiencia del programa.
            \item Incluye la eliminación de código inaccesible y la optimización de bucles.
            \item Esencial para mejorar el rendimiento y la eficiencia del código compilado.
        \end{itemize}

    \item \textbf{Generación de código máquina}:
        \begin{itemize}
            \item Convierte la representación intermedia en código de máquina ejecutable por el procesador.
            \item El código generado está optimizado para el hardware específico de destino.
            \item Completa el proceso de traducción resultando en un programa ejecutable o archivo objeto.
        \end{itemize}
\end{enumerate}


A diferencia de los compiladores, un \textbf{intérprete} no genera un archivo de salida ejecutable. En su lugar, leen y ejecutan el código fuente directamente, traduciendo el programa a medida que se ejecuta. Esto permite una mayor flexibilidad y una iteración más rápida durante el desarrollo, aunque puede tener un rendimiento más lento en comparación con los programas compilados. Los intérpretes también utilizan técnicas de análisis léxico y sintáctico para entender el código fuente, pero ejecutan las instrucciones inmediatamente después de su análisis.

También hay una variante que combina ambos enfoques, que es lo que se denomina como \textbf{compilador híbrido}. En la práctica en este proyecto, aunque se dispone de una fase de compilación que traduce código del lenguaje a código intermedio, su funcionamiento es más semejante al de un \textit{intérprete}, al traducir inmediatamente dichas instrucciones intermedias.