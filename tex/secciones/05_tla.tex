\chapter{\textbf{Verificación formal de sistemas concurrentes: Lógica Temporal de Acciones}}\label{chapter:tla}
La estrecha colaboración entre la informática y las matemáticas se evidencia especialmente en el ámbito de la verificación formal de sistemas concurrentes, cuya misión es asegurar que los sistemas que requieren de múltiples procesos ejecutándose simultáneamente sean correctos y fiables. La \textit{corrección}, en el contexto de los algoritmos concurrentes, implica la satisfacción de las propiedades deseadas del programa. Este capítulo se centra en la Lógica Temporal de Acciones (TLA), una creación de Leslie Lamport y que tiene como objetivo especificar y verificar las propiedades de estos sistemas mediante fórmulas.

La motivación detrás de la definición de TLA por parte de Lamport radica en su convicción de que utilizar un razonamiento riguroso es la única manera de prevenir errores graves en algoritmos concurrentes. Esta percepción lleva al planteamiento de dos preguntas: ¿Por qué optar por una lógica en lugar de un lenguaje de programación convencional? ¿No sería más sencillo trabajar directamente con programas en lugar de fórmulas lógicas? La respuesta a ambas es no. ``\textit{La lógica es la formalización de las matemáticas de toda la vida, y las matemáticas de toda la vida son más simples que los programas}'', según comenta Lamport, no sin razón. Un lenguaje de programación puede usar términos matemáticos como \textit{función}, pero los constructos que representa no son tan simples como sus correspondientes conceptos matemáticos. Las funciones matemáticas son simples, mientras que en la mayoría de lenguajes de programación las funciones envuelven conceptos adicionales y complejos como \textit{expresión de retorno}, \textit{convención de llamada}, etc.

TLA combina dos lógicas: la lógica de acciones, que se centra en las transiciones de estados en un sistema, y la lógica temporal estándar, que permite razonar sobre el comportamiento del sistema a lo largo del tiempo. Esta integración permite a TLA capturar con precisión tanto la dinámica de los estados individuales como la evolución global de un sistema concurrente.

\section{Conceptos básicos de sistemas concurrentes}\label{section:concurrentprop}
Antes de profundizar en el análisis y la aplicación de la Lógica Temporal de Acciones, resulta fundamental entender los conceptos básicos de la programación concurrente. Esta sección se dedica a presentarlos, estableciendo así una base sólida para apreciar la relevancia y la efectividad de TLA en la verificación de programas.

En primer lugar, debe quedar claro lo que es un programa secuencial. Un \textbf{programa secuencial} consta de un conjunto de declaraciones de datos más un conjunto de instrucciones sobre dichos datos que se ejecutan en secuencia. Ahora, se puede definir un \textbf{programa concurrente} como el conjunto de programas secuenciales ordinarios que se pueden ejecutar \textit{lógicamente} en paralelo, y cada programa secuencial es ejecutado por un \textbf{proceso}. Finalmente, la \textbf{programación concurrente} es el conjunto de notaciones y técnicas de programación utilizas para expresar paralelismo potencial y resolver problemas de sincronización y comunicación.

\subsection{Modelos de arquitecturas de programación concurrente}\label{subsec:concurrentarch}
De la definición anterior de programa concurrente, cabe destacar la importancia de decir que los programas pueden ejecutarse \textit{lógicamente} en paralelo. Esto quiere decir que la concurrencia en un sistema se puede gestionar de diversas maneras, dando lugar a un paralelismo real o ilusorio. Es por ello que se se disponen de tres modelos diferentes de concurrencia basados en la arquitectura hardware:

\begin{itemize}
    \item \textbf{Concurrencia en sistemas monoprocesador}: Puesto que sólo hay una CPU disponible, se trabaja sobre un sistema operativo multiprogramación, gestionando cómo múltiples procesos se reparten ciclos de procesador. Los mecanismos de sincronización y comunicación se hace mediante variables compartidas.
    \item \textbf{Concurrencia en sistemas multiprocesador de memoria compartida}: Los procesadores pueden compartir o no físicamente la misma memoria, pero sí disponen de un espacio de direcciones compartido. La interacción de los procesos en este modelo también se realiza mediante variables compartidas.
    \item \textbf{Concurrencia en sistemas distribuidos}: Aquí también hay múltiples procesadores. No existe una memoria común, cada procesador tiene su espacio de direcciones privado. La interacción se realiza transfiriendo datos entre procesos a través de una red de interconexión (paso de mensajes).
\end{itemize}

\subsection{Instrucciones atómicas y entrelazamiento}\label{subsec:concurrentatomic}
Una instrucción (o sentencia) de un proceso en un programa concurrente es \textbf{atómica} si siempre se ejecuta de principio a fin sin verse afectada durante su ejecución por las instrucciones de otros procesos del programa que también estén en ejecución. En otras palabras, no se verá afectada cuando el \textit{funcionamiento} de dicha instrucción \textit{no dependa nunca} de cómo estén ejecutando otras instrucciones, entendiéndose por \textit{funcionamiento de instrucción} como el efecto en el estado de ejecución del programa justo cuando ésta acaba. Como ejemplo de instrucciones atómicas se pueden considerar muchas de las instrucciones máquina de un procesador como es el caso de las instrucciones de carga (\code{LOAD}) y almacenamiento (\code{STORE}) que operan entre los registros de CPU y las celdas de memoria. Mientras tanto, un ejemplo de instrucción no atómica puede ser \code{x = x+1}. Aquí, se ejecutan 3 instrucciones diferentes: primero se carga el valor de la variable \code{x} en un registro; segundo se incrementa el valor del registro en \code{1}, y finalmente, el resultado de esa operación se almacena en la celda de memoria de la variable \code{x}. El valor de la variable \code{x} justo cuando termine la ejecución de la instrucción no atómica dependerá de que haya o no haya otras sentencias ejecutándose a la vez y que intenten escribir simultáneamente en dicha variable. Cuando eso sucede, se dice que existe \textit{indeterminación}, pues no se puede predecir el estado final del proceso a partir de su estado inicial.

Tras comprender las instrucciones atómicas y la indeterminación que surge con las no atómicas, es crucial abordar el entrelazamiento en programas concurrentes. El \textbf{entrelazamiento} se refiere a la manera en que las instrucciones de diferentes procesos se intercalan o ``entrelazan'' durante la ejecución. En un sistema concurrente, múltiples procesos avanzan aparentemente en paralelo, pero en realidad, sus instrucciones pueden ser ejecutadas de forma intercalada por el procesador. Esto significa que la secuencia exacta de ejecución de instrucciones entre procesos concurrentes puede variar de una ejecución a otra, lo que introduce un nivel significativo de no determinismo en el sistema. Por ejemplo, si dos procesos intentan modificar una misma variable compartida (como podría ser el caso en el ejemplo anterior con la variable \code{x}) sin mecanismos adecuados de sincronización, el resultado final puede depender del orden específico en que se ejecuten sus instrucciones respectivas. Este comportamiento impredecible, inherente al entrelazamiento, es una fuente principal de condiciones de carrera y otros problemas relacionados con la sincronización en sistemas concurrentes. Por lo tanto, entender y manejar el entrelazamiento es fundamental para asegurar la corrección y la estabilidad de estos sistemas, preparando el camino para explorar cómo las técnicas de sincronización y las herramientas como TLA que se verán más adelante pueden ayudar en este proceso.

\subsection{Independencia del entorno de ejecución: Hipótesis del progreso finito}\label{subsec:concurrentprogfinit}
El modelo basado en el estudio de todas las posibles secuencias de los procesos de un programa concurrente constituye una \textbf{abstracción}, donde se consideran sólo las características relevantes que determinan el resultado final del programa, ignorando otras como el estado de la memoria asignado a cada proceso, los registros particulares a los que accederá cada uno, el costo de cambios de contexto entre procesos que hace el sistema operativo, la política de planificación y las diferencias de velocidad entre entornos multiprocesador y monoprocesador. Además, el entrelazamiento de instrucciones atómicas preserva la consistencia de los resultados, pues en caso contrario, sería imposible poder razonar sobre las propiedades de corrección de los programas concurrentes que se hablarán más adelante. Es por ello que, para esa corrección de los programas concurrentes, se utiliza la hipótesis siguiente.

\subsubsection{Hipótesis del progreso finito}\label{subsubsec:concurrentprogfinithip}
El enunciado de la hipótesis es: \textit{No se puede hacer ninguna suposición acerca de las velocidades absolutas o relativas de ejecución de los procesos, salvo que es mayor que cero. Un programa concurrente se entiende sólo con base en sus componentes (procesos) y sus interacciones, sin tener en cuenta el entorno de ejecución.} Si se hicieran suposiciones que dependiesen del tiempo o de la velocidad de ejecución de los procesos, sería difícil detectar y corregir fallos y además, la corrección dependería de la configuración de ejecución, que puede cambiar.

\subsection{Exclusión mutua y sincronización}\label{subsec:concurrentexclusion}
No todas las secuencias de entrelazamiento de las instrucciones de los procesos que pueden producirse en un programa concurrente son posibles en la realidad, pues los procesos no suelen ejecutarse de una forma totalmente independiente, sino que colaboran entre ellos. Se denomina \textbf{condición de sincronización} a la restricción en el orden en que se pueden entremezclar las instrucciones que generan los procesos de un programa. Cuando se impone una condición de sincronización, uno o varios procesos deben esperar a que se cumpla una determinada condición global que depende de varios procesos. Un ejemplo de condición de sincronización sencillo puede ser el de observar el valor de una variable global compartida entre varios procesos.

\subsubsection{Sección crítica y exclusión mutua}\label{subsubsec:concurrentsc}
Al conjunto de secuencias comunes de instrucciones consecutivas que aparecen en varios procesos de un programa concurrente se denomina \textbf{sección crítica} (SC). Además, se dice que ocurre \textbf{exclusión mutua} (EM) cuando los procesos sólo funcionan correctamente si, en cada instante de tiempo, hay como mucho uno de ellos ejecutando cualquier instrucción de la sección crítica.

\subsection{Corrección y propiedades de los sistemas concurrentes}\label{subsec:concurrentproperties}
Esta subsección es imprescindible para el propósito de este capítulo, pues el objetivo es ofrecer un razonamiento preciso y eficaz sobre las propiedades que cumple un programa concurrente, utilizando para ello la Lógica Temporal de Acciones. Se entiende por \textbf{propiedad} a un atributo de un programa concurrente que es cierto para todas las posibles secuencias de entrelazamiento. Hay dos principales tipos de propiedades:

\begin{enumerate}[label=P\arabic*]
    \item \textbf{Propiedad de seguridad (safety)}: ``\textit{Nunca pasará nada malo}''. Son condiciones que deben cumplirse \textit{siempre}. Ejemplos de propiedades de seguridad son:
    \begin{enumerate}[label=P1.\arabic*]
        \item \textit{Exclusión Mutua (Mutual Exclusion)}: Dos procesos nunca entrelazan ciertas subsecuencias de operaciones.
        \item \textit{Ausencia de Interbloqueo (Deadlock-freedom)}: Nunca ocurrirá que los procesos se encuentren esperando algo que nunca sucederá.
    \end{enumerate}
    \item \textbf{Propiedad de vivacidad (liveness)}: ``\textit{Realmente sucede algo bueno}''. Son condiciones que deben cumplirse \textit{eventualmente}. Ejemplos de propiedades de vivacidad son:
    \begin{enumerate}[label=P2.\arabic*]
        \item \textit{Ausencia de inanición (starvation-freedom)}: Un proceso o grupo de procesos no puede ser indefinidamente pospuesto. En algún momento, podrá avanzar.
        \item \textit{Equidad (fairness)}: Tipo particular de propiedad de vivacidad. Un proceso que desee progresar debe hacerlo con justicia relativa con respecto a los demás.
    \end{enumerate}
\end{enumerate}

\section{La Lógica Temporal de Acciones (TLA)}\label{section:TLA}
Tras establecer los fundamentos de la programación concurrente, sus características inherentes y las propiedades que puede poseer un programa concurrente, se aborda la sección central de este capítulo: el estudio de la Lógica Temporal de Acciones (TLA) \cite{lamport1994temporal}. Como se mencionó anteriormente, TLA se origina de la combinación de dos lógicas fundamentales: la lógica de estados y la lógica temporal estándar. En su estructura, TLA se fundamenta en la lógica de predicados ordinaria, ampliada con dos tipos de variables: las \textit{variables rígidas}, comúnmente referidas como constantes, y las \textit{variables flexibles}, correspondientes a las variables de programa en las especificaciones. TLA incorpora operadores clásicos de la lógica (como $\land$, $\lor$, $\implies$),  incluyendo ahora nuevos como los cuantificadores $\forall$ y $\exists$. También el operador $'$ (prima), que funciona como el operador de estado siguiente (next) en la lógica temporal, utilizado para describir transiciones entre estados. Además, se incluye el operador ``$\Box$'' (siempre), esencial para especificar propiedades temporales y reflejar la naturaleza evolutiva y continua de los sistemas que TLA busca modelar. Se introducirán más operadores que resultan de la combinación de los operadores primitivos.

\subsection{Lógica de acciones}\label{subsection:LActions}
En la manipulación de datos por algoritmos, se realiza frecuentemente la asignación de valores a variables. Se define $Val$ como un conjunto que comprende \textit{valores} diversos, incluyendo números enteros, números reales, cadenas de caracteres y conjuntos tales como los números naturales, representados por $Nat$ \footnote{Se define $Nat$ como $\mathbb{N} \cup {0}$, incluyendo el cero.}. Adicionalmente, $Var$ se identifica como el conjunto de todos los nombres posibles para las variables, ejemplificados por $x$ o $nombre$. En otro aspecto, la lógica se caracteriza por un conjunto de reglas para la manipulación de fórmulas. Sin embargo, para la comprensión del significado de dichas fórmulas y sus procesos de manipulación, es imprescindible la presencia de una \textit{semántica}. Se utiliza la notación $[[F]]$ para indicar el significado semántico de cada elemento sintáctico $F$ en la lógica.\footnote{La notación $[[\cdot]]$ se interpreta como una función entre conjuntos. A lo largo del documento, se procederá a definir formalmente cada elemento lógico, utilizando de manera consistente el mismo término para todas las funciones semánticas.}

En esta lógica, la semántica se define a través del concepto de estados. Se entiende por \textbf{estado} a una función específica que asigna valores a las variables, es decir, una función que conecta el conjunto de variables con su respectiva colección de valores:

\begin{align*}
s : Var &\to Val \\
x &\mapsto s(x)
\end{align*}

El conjunto que incluye todos los estados posibles se representa como $St$. El término $s[[x]]$ se utiliza para referirse a $s(x)$, interpretando el significado $[[x]]$ de la variable $x$ como la función que relaciona los estados con sus valores, aplicando una notación de posfijo para la función. De manera formal, esto se define como:

\begin{align*}
[[\cdot]] : Var &\to (St \to Val) \\
[[x]] &\mapsto (s \mapsto s(x))
\end{align*}

Después de establecer una comprensión básica de los elementos más sencillos, es apropiado introducir las \textbf{expresiones} lógicas, que se forman utilizando operadores y otros elementos como variables, constantes y expresiones del tipo $o(e_1,\ldots,e_n)$, en las cuales $o$ representa un operador y cada $e_i$ es una expresión. Un ejemplo es $+(x,y)$, aunque convendrá escribirlo como $x+y$. Cada operador $o$ tiene un significado semántico asignado, representado por $[[o]]$. Así, el significado de una expresión compuesta como $+(e_1,e_2)$ se establece de manera inductiva. En un estado $s$, esta expresión se interpreta como $[[+]](s[[e_1]],s[[e_2]])$, aplicando el significado semántico del operador a los valores de las subexpresiones en ese estado.

Es importante mencionar que bajo los fundamentos de la teoría de conjuntos, es posible representar todos los operadores requeridos en esta lógica con un conjunto limitado de operadores primitivos, como $\land$ (y), $\neg$ (no), $\in$ (pertenencia) y $\epsilon$ (elección de Hilbert). Esta aproximación facilita la formulación y entendimiento de las expresiones. Habitualmente, se emplea una notación simplificada que no diferencia entre un operador y su interpretación semántica. Por ejemplo, en vez de detallar la expresión semántica completa $s[[x+y]]$, se abrevia a $s[[x]] + s[[y]]$, lo que simplifica la lectura y análisis de las expresiones en este marco.

Se identifican tres categorías de expresiones. Las $\textbf{funciones de estado}$ son expresiones como $x + y^2 - 7$. Se define $StFunc$ como el conjunto de estas funciones de estado. El significado $[[f]]$ de una función $f$ es una aplicación desde el conjunto $St$ de estados hacia la colección $Val$ de valores:

\begin{align*}
[[\cdot]] : StFunc &\to (St \to Val) \\
[[f]] &\mapsto (s \mapsto s[[f]] \triangleq f(\forall 'v' : s[[v]] / v)) \hspace{0.1cm}\textsuperscript{\dag}
\end{align*}

\footnotetext{\dag \hspace{0.1cm} $\triangleq$ significa ``igual por definición''.}


donde $f(\forall 'v' : s[[v]]/v)$ indica el valor resultante de $f$ al sustituir $s[[v]]$ (el valor de la variable) por $v$, para cada variable $v$. En el caso mencionado, $[[x + y^2 - 7]]$ otorga a un estado $s$ el valor $s[[x]] + s[[y]]^2 -7$, donde $2$ y $7$ son constantes simbólicas que también representan los valores que simbolizan. No se realiza distinción entre símbolos constantes y sus valores representativos.

Se considera que una variable $x$ actúa igualmente como una función de estado. Por lo tanto, la definición de $[[f]]$ para una función de estado $f$ se aplica también a la definición de $[[x]]$ para una variable $x$.

El segundo tipo de expresión se conoce como \textbf{predicado de estado} (a menudo referido simplemente como \textbf{predicado}), y se construye de manera similar a las funciones de estado. Ejemplos de predicados incluyen $x^2 = y -3$ y $x \in Nat$. El conjunto que engloba a todos los predicados de estado se designa como $StPred$. La distinción principal entre las funciones de estado y los predicados radica en su significado. El significado $[[P]]$ de un predicado $P$ se define como una función que asocia el conjunto de estados $St$ con el conjunto de valores de verdad, que se representa por $\left\lbrace \top, \bot\right\rbrace$ (verdadero y falso, respectivamente):

\begin{align*}
[[\cdot]] : StPred &\to (St \to \left\lbrace \top, \bot \right\rbrace) \\
[[P]] &\mapsto (s \mapsto s[[P]])
\end{align*}

La última categoría de expresión en esta lógica es fundamental y se define como una \textbf{acción}. Consiste en una expresión compuesta por variables, variables alteradas (indicadas con prima) y símbolos constantes. Expresiones tales como $x' + 1 = y$ y $x-1 \not \in z'$ son ejemplos de acciones, donde $x,y,z$ son variables. Dichas acciones establecen una conexión entre estados previos y estados posteriores; las variables sin prima denotan el estado previo, mientras que las variables con prima aluden al estado posterior. Por ejemplo, en $z = y' - 1$, se interpreta que el valor de $z$ en el estado anterior es inferior al valor de $y$ en el estado posterior.

Formalmente, el significado $[[\mathcal{A}]]$ de una acción $\mathcal{A}$ se entiende como una relación entre dos estados, es decir, una función que asigna un valor de verdad $s[[\mathcal{A}]]t$ a una pareja de estados $\langle s,t \rangle$. Al conjunto de estas acciones se le denomina $Act$. Por lo tanto, el valor de verdad $s[[\mathcal{A}]]t$ se determina considerando a $s$ como el \textit{estado anterior} y a $t$ como el \textit{estado subsiguiente}. Esto se logra en $\mathcal{A}$ sustituyendo cada variable $v$ sin prima por su valor en $s$ ($s[[v]]$) y cada variable con prima $v'$ por su valor en $t$ ($t[[v]]$).

\begin{align*}
[[\cdot]] : Act &\to (St \times St \to \left\lbrace \top, \bot \right\rbrace) \\
[[\mathcal{A}]] &\mapsto ((s,t) \mapsto s[[\mathcal{A}]]t \triangleq \mathcal{A}(\forall 'v' : s[[v]] / v, t[[v]] / v'))
\end{align*}

Con el ejemplo anterior $z = y' - 1$, quedaría entonces $[[z = y' - 1 ]] = s[[z]] = t[[y]] - 1$. Al par de estados $\langle s,t\rangle$ se le nombra como \textbf{$\mathcal{A}$ paso} si, y sólo si, $s[[\mathcal{A}]]t$ se evalúa como verdadero ($\top$). Ahora, $\mathcal{A}$ se dice que es una \textbf{acción válida}, escrito como $\models \mathcal{A}$, si y sólo si todo paso es un $\mathcal{A}$ paso. Formalmente:

\begin{align}
\models \mathcal{A} \triangleq \forall s,t \in St : s[[\mathcal{A}]]t
\end{align}

Con esta nueva definición de acción, y recordando la definición de predicado, se puede ver a $P$ como una acción que no contiene variables con prima. Un par de estados $\langle s,t \rangle$ es un \textbf{$P$ paso sí} y sólo sí $s$ satisface $P$, o en otras palabras, $s[[P]]t = s[[P]]$ se evalúa como verdadero. Para cualquier función de estado o predicado $F$, se define ahora $F'$ como la expresión obtenida de la sustitución de cada variable $v$ de $F$ por la variable con prima $v'$:

\begin{align}
F' \triangleq F(\forall 'v' : v' / v)
\end{align}

En particular, si $P$ es un predicado, entonces $P$ es una acción, y $s[[P']]t = t[[P]]$ para todo par de estados $\langle s,t \rangle$. También las funciones de estado pueden llevar prima, y se denomina \textit{Unchanged} $f$ como:

\begin{align}
\textit{Unchanged} \hspace{0.2cm} f \triangleq f = f'
\end{align}

es decir, \textit{Unchanged} $f$ es una acción y se dice que es un \textit{paso tartamudo}, donde $f$ no cambia. Se puede considerar también combinar acciones con funciones de estado. Dada una acción $\mathcal{A}$ y una función de estado $f$ se define también $[\mathcal{A}]_f$ como:

\begin{align}
[\mathcal{A}]_f \triangleq \mathcal{A} \lor \textit{Unchanged} \hspace{0.2cm} f \triangleq \mathcal{A} \lor (f = f')
\end{align}

y se dice que o es un $\mathcal{A}$ paso o un paso tartamudo (con respecto a $f$). Por otro lado también se encuentra su forma dual $\langle \mathcal{A} \rangle_f$:

\begin{align}
\langle\mathcal{A}\rangle_f \triangleq \mathcal{A} \land \neg(\textit{Unchanged} \hspace{0.2cm} f) \triangleq \mathcal{A} \land \neg(f = f')
\end{align}

\noindent
que indica que es un $\mathcal{A}$ paso que necesariamente cambia $f$.

En el caso de cualquier acción $\mathcal{A}$, se establece el predicado \textit{Enabled} $\mathcal{A}$ que resulta verdadero para un estado específico únicamente si es factible ejecutar un paso de $\mathcal{A}$ comenzando desde ese estado. Desde el punto de vista sintáctico, este nuevo predicado puede describirse de la siguiente manera. Suponiendo que $v_1,\ldots,v_n$ son variables flexibles\footnote{Dentro del contexto de la lógica modal y otros sistemas lógicos, es importante diferenciar entre las variables rígidas y las flexibles. Las variables rígidas mantienen su valor constante en diferentes contextos o mundos posibles, presentando una naturaleza invariable y estable, independientemente del estado o situación. En contraste, las variables flexibles tienen valores que varían según el contexto o mundo posible específico. Estas variables no poseen un valor fijo, lo que les permite adaptarse a diversas situaciones o estados dentro de un sistema lógico. Esta distinción es esencial para comprender la interpretación y asignación de valores a las variables en distintos contextos lógicos y mundos posibles.} que aparecen en $\mathcal{A}$, entonces:

\begin{align}
\textit{Enabled} \hspace{0.2cm} \mathcal{A} \triangleq \exists c_1,\ldots,c_n : \mathcal{A}(c_1 / v_1', \ldots c_n / v_n')
\end{align}

donde $\mathcal{A}(c_1 / v_1', \ldots c_n / v_n')$ denota la fórmula obtenida de la sustitución de nuevas variables rígidas \footnote{Ver nota inmediatamente anterior.} $c_i$ por todas las ocurrencias de $v_i'$ en $\mathcal{A}$. Su semántica se define de esta forma para cualquier estado $s$:

\begin{align}
s[[\textit{Enabled} \hspace{0.2cm} \mathcal{A}]] \triangleq \exists t \in St : s[[\mathcal{A}]]t
\end{align}

Hasta ahora, es fundamental resaltar cómo esta lógica de acciones se relaciona con los sistemas concurrentes. En TLA, una instrucción atómica (como se menciona en~\ref{subsec:concurrentatomic}) se representa por una acción $\mathcal{A}$, y un par $(s,t)$ constituye un paso $\mathcal{A}$ si y solo si la ejecución de la instrucción en el estado $s$ resulta en el estado $t$. Adicionalmente, si una acción $\mathcal{A}$ simboliza una instrucción atómica, entonces el predicado \textit{Enabled} $\mathcal{A}$ es verdadero para todos los estados donde la instrucción es ejecutable.

\subsection{Lógica Temporal}\label{subsection:LTemporal}
Una \textbf{fórmula temporal} se compone de fórmulas básicas combinadas con operadores clásicos ($\land$, $\neg$), y el operador unario $\Box$, que se interpreta como \textit{siempre}. Vale la pena señalar que otros operadores que se mencionarán más adelante se definen usando $\land$ y $\neg$. Un ejemplo de una fórmula temporal es $F \land \Box(\neg G)$, donde $F,G$ son fórmulas básicas. El conjunto total de fórmulas, incluyendo las temporales y las básicas, se denomina $Form$.

La semántica de la lógica temporal se centra en los \textit{comportamientos}, donde un \textbf{comportamiento} es una serie infinita de estados. Este enfoque es útil para hacer una comparación con lo que sucede en la ejecución de un algoritmo por una máquina, cubriendo también casos de secuencias finitas de estados que marcan el fin de un programa\footnote{Aun así, considerar secuencias infinitas de estados es adecuado y suficiente.}. El conjunto de todos los comportamientos se representa como $St^\infty$. Para entender el significado de una fórmula temporal, es necesario analizar las fórmulas elementales que contiene, o sea, basta con definir la semántica de $[[F \land G]]$, $[[\neg F]]$ y $[[\Box F]]$ en términos de $[[F]]$ y $[[G]]$.

La interpretación de una fórmula temporal implica hacer una afirmación acerca de los comportamientos. De forma formal, el significado $[[F]]$ de una fórmula $F$ es el valor de verdad que esta fórmula asigna a un comportamiento $\sigma$:

\begin{align*}
[[\cdot]] : Form &\to (St^\infty \to \left\lbrace \top, \bot \right\rbrace) \\
[[F]] &\mapsto (\sigma \mapsto \sigma[[F]])
\end{align*}

Se dice además que $\sigma$ satisface $F$ si y sólo si $\sigma[[F]]$ se evalúa como verdadera. Ahora, ya se pueden definir también los significados de $[[F \land G]]$ y $[[\neg F]]$:

\begin{gather*}
\sigma [[F \land G]] \triangleq \sigma[[F]] \land \sigma[[G]] \\
\sigma [[\neg F]] \triangleq \neg \sigma[[F]]
\end{gather*}

Por tanto, un comportamiento $\sigma$ satisface $F \land G$ si satisface a ambas fórmulas, y satisface a $\neg F$ si y sólo si no satisface a $F$. Ahora, se pueden derivar fórmulas similares para otros operadores:

\begin{gather*}
F \implies G \equiv \neg (F \land \neg G) \\
F \lor G \equiv \neg (\neg F \land \neg G)
\end{gather*}

\noindent
y su respectivo significado semántico como:

\begin{align*}
\sigma[[F \implies G]] &\equiv \sigma[[\neg (F \land \neg G)]] \\
&\triangleq \neg\sigma [[F \land \neg G]] \\
&\triangleq \neg(\sigma[[F]] \land \neg\sigma[[G]]) \\
&\triangleq \sigma[[F]] \implies \sigma[[G]]
\end{align*}

\begin{align*}
\sigma[[F \lor G]] &\equiv \sigma[[\neg (\neg F \land \neg G)]] \\
&\triangleq \neg \sigma[[\neg F \land \neg G]] \\
&\triangleq \neg (\neg\sigma[[F]] \land \neg\sigma[[G]]) \\
&\triangleq \sigma[[F]] \lor \sigma[[G]]
\end{align*}

Para definir el significado de $[[\Box F]]$, que es la única que faltaba, se hará en términos de $[[F]]$. Sea $\sigma = \langle s_0, s_1, \ldots \rangle$ el comportamiento cuyos estados están numerados de forma natural (el primer estado es $s_0$, el siguiente $s_1$, y así sucesivamente). Entonces:

\begin{align}
\sigma[[\Box F]] \triangleq \forall n \in Nat : \langle s_n, s_{n+1}, s_{n+2}, \ldots \rangle[[F]]
\end{align}

Esta interpretación sigue los preceptos clásicos de la lógica temporal lineal. Se puede comprender el comportamiento $\sigma$ como la evolución del universo, donde $s_n$ indica el estado del universo en el instante de tiempo $n$. $\sigma[[\Box F]]$ indica por tanto, que $F$ es verdadera en todos los tiempos durante el comportamiento $\sigma$, o dicho de otra manera, $\Box F$ asegura que $F$ es verdad \textit{siempre}.

\subsection{Fórmulas temporales. Validez}\label{subsection:LTForms}
A continuación se presentan algunas de las fórmulas temporales que se utilizarán de aquí en adelante, teniendo en cuenta todo el marco teórico visto en la sección anterior. Estas fórmulas tienen su importancia en la verificación de programas concurrentes, donde ya se están empezando a ver dichos programas como objetos matemáticos, en términos de \textit{acciones} y \textit{comportamientos}.

\subsubsection{Eventualidad}\label{subsubsection:LTFormsEventually}
\noindent
Para cualquier fórmula $F$, se define $\Diamond F$ como:

\begin{align}
\Diamond F \triangleq \neg \Box \neg F
\end{align}

Esta fórmula asegura que no siempre $F$ es falso, o en otras palabras, $F$ es \textit{eventualmente} verdad. El significado semántico de esta fórmula se puede expresar teniendo en cuenta las relaciones entre los cuantificadores universales, pues $\neg\forall\neg \equiv \exists$, por lo que:

\begin{align}
\sigma[[\Diamond F]] \equiv \exists n \in Nat : \langle s_n, s_{n+1}, s_{n+2}, \ldots \rangle[[F]]
\end{align}

para cualquier comportamiento $\sigma = \langle s_0, s_1, s_2, \ldots \rangle$. La fórmula $\Diamond F$ asegura que $F$ es verdad en algún punto del comportamiento.

\subsubsection{Infinitamente a menudo}
Para cualquier fórmula $F$, y combinando los operadores siempre ($\Box$) y eventualmente ($\Diamond$), se define la fórmula:

\begin{align}
\Box \Diamond F
\end{align}

Esta fórmula se lee como que \textit{$F$ es cierta infinitamente a menudo}, y será cierta para un comportamiento $\sigma = \langle s_0, s_1, \ldots \rangle \in St^\infty$ si y sólo si $\Diamond F$ es cierta en todos los tiempos $n$ durante ese comportamiento, y $\Diamond F$ será cierta si y sólo si existe un tiempo $m$ mayor o igual a $n$ donde $F$ es cierta. Formalmente:

\begin{align}
\sigma [[\Box \Diamond F]] \equiv \forall n \in Nat : \exists m \in Nat : \langle s_{n+m}, s_{n+m+1},\ldots \rangle [[F]]
\end{align}

\subsubsection{Eventualmente siempre}
Para cualquier fórmula $F$ y de forma similar a la anterior fórmula temporal, se define la fórmula:

\begin{align}
\Diamond \Box F
\end{align}

Esta fórmula se lee como que \textit{eventualmente, $F$ es cierta siempre}, y será cierta para un comportamiento $\sigma = \langle s_0, s_1, \ldots \rangle$ si y sólo si existe algún tiempo $m$ tal $F$ es verdad a partir de ese momento. Formalmente:

\begin{align}
\sigma [[\Diamond \Box F]] \equiv \exists m \in Nat : \forall n \geq m : \langle s_{n}, s_{n+1}, \ldots \rangle [[F]]
\end{align}

\subsubsection{Conduce a}
\noindent
Para cualquier par de fórmulas $F,G$ se define:

\begin{align}
F \leadsto G \triangleq \Box(F \implies \Diamond G)
\end{align}

El operador ($\leadsto$) se lee como \textit{conduce a}, y la fórmula asegura que siempre se da el caso de que si F es verdadero, entonces G es verdadero ahora o en algún momento posterior. Si $F \leadsto G$ y $G \leadsto H$, entonces $F \leadsto H$.

\subsubsection{Justicia (fairness)}
En la sección referenciada como ~\ref{subsec:concurrentproperties}, se abordaron las propiedades que puede tener un programa concurrente, incluyendo su interpretación. TLA facilita el análisis de si un programa cumple con la propiedad de justicia, una categoría específica dentro de las propiedades de vivacidad. Empleando términos previamente mencionados, la \textit{justicia} puede entenderse como la garantía de que una instrucción en particular será ejecutada por el programa en algún momento, siempre que sea factible. Se identifican dos variantes de justicia: la \textit{justicia débil} y la \textit{justicia fuerte}.

En el caso de la justicia débil, se establece que una instrucción específica del programa será ejecutada en algún momento o se volverá eventualmente imposible de ejecutar. En cuanto a la justicia fuerte, se sostiene que la instrucción será ejecutada eventualmente o que su ejecución no será infinitamente a menudo posible. Al afirmar que estas condiciones se cumplen en todo momento, las expresiones para estas propiedades (definidas aún de manera informal) serían:

\begin{align*}
\textit{justicia débil}: \hspace{0.3cm} (\Box\Diamond \text{ejecutado}) \lor (\Box\Diamond \text{imposible}) \\
\textit{justicia fuerte}: \hspace{0.3cm} (\Box\Diamond \text{ejecutado}) \lor (\Diamond\Box \text{imposible}) \\
\end{align*}

queda sólo por determinar el concepto de ``ejecutado'' e ``imposible''. ``Ejecutar'' una instrucción significa tomar un $\langle \mathcal{A}\rangle_f$ (ver definición 5.5) paso, para alguna acción $\mathcal{A}$ y una función de estado $f$, y es posible tomarlo  si y sólo si \textit{Enabled} $\langle \mathcal{A}\rangle_f$ es cierta. Por lo tanto, \textit{Enabled} $\langle A \rangle_f$ aserta que es posible ejecutar la instrucción representada por la acción $\langle \mathcal{A}\rangle_f$, designando por ``imposible'' entones $\neg$\textit{Enabled} $\langle \mathcal{A}\rangle_f$. Ahora sí se puede hacer una definición formal de las fórmulas de justicia débil (WF) y fuerte (SF):

\begin{align}
\text{WF}_f(\mathcal{A}) \triangleq (\Box\Diamond \langle \mathcal{A}\rangle_f) \lor (\Box\Diamond \neg \textit{Enabled} \hspace{0.1cm} \langle \mathcal{A}\rangle_f) 
\end{align}

\begin{align}
\text{SF}_f(\mathcal{A}) \triangleq (\Box\Diamond \langle \mathcal{A}\rangle_f) \lor (\Diamond\Box \neg \textit{Enabled} \hspace{0.1cm} \langle \mathcal{A}\rangle_f) 
\end{align}

Una consecuencia directa de esta definición, y utilizando la siguiente tautología de la lógica modal \footnote{Se recuerda que la lógica temporal, es una extensión de la lógica modal, por lo que muchas de sus conectivas, reglas, y tautologías, siguen manteniéndose.} $\Diamond\Box F \implies \Box\Diamond F$ para cualquier fórmula $F$, es que:

\begin{align}
\text{SF}_f(\mathcal{A}) \implies \text{WF}_f(\mathcal{A})
\end{align}

\subsubsection{Validez de fórmulas temporales}
Tras haber mostrado algunas de las fórmulas temporales más útiles, hay que precisar la definición de fórmula válida. Una fórmula temporal es \textbf{válida}, escrito como $\models F$ si y sólo si es satisfecha para todos los comportamientos posibles. Esto se traduce en:

\begin{align}
\models F \triangleq \forall \sigma \in St^\infty : \sigma[[F]]
\end{align}

\subsubsection{Fórmulas temporales y programas concurrentes}
Los programas concurrentes y sus propiedades serán representadas como fórmulas temporales, tal y como se esperaba en el propósito marcado de ofrecer un formalismo matemático para la corrección. Puesto que un comportamiento modela una ejecución de un programa concurrente, se dirá que $\models F \implies G$ cuando el algoritmo o programa $F$ satisface la propiedad $G$, $\forall \sigma \in St^\infty$.

\subsection{Características adicionales de la TLA}
Hasta el momento, se han visto todos los objetos que conforman la Lógica Temporal de Acciones: los estados, las expresiones y las fórmulas temporales. Con todas estas herramientas, el siguiente objetivo es realizar una descripción de las reglas que la conforman, además de hacer alguna que otra consideración adicional.

En \ref{subsection:LActions} se definió que, si $\mathcal{A}$ es una acción, $\langle s,t \rangle$ es un $\mathcal{A}$ paso si y sólo si $s[[\mathcal{A}]]t$ es verdadera, donde $s[[\mathcal{A}]]t$ es el significado semántico que se le otorgó a $[[\mathcal{A}]]$. Ahora, tomando $\sigma = \langle s_0, s_1, \ldots \rangle \in St^\infty$, se puede extender el significado semántico de $[[\mathcal{A}]]$ como sigue: 

\begin{align}
\sigma[[\mathcal{A}]] = \langle s_0, s_1, s_2, \ldots \rangle[[\mathcal{A}]] \triangleq s_0[[\mathcal{A}]]s_1
\end{align}

Por otra parte, también se introdujo lo que se denominó \textit{pasos tartamudos} en funciones de estado, esto es cuando $f = f'$, siendo $f$ función de estado. Dada cualquier acción $\mathcal{A}$ y una función de estado $f$ se introdujo la notación $[\mathcal{A}]_f$ (ver definición 5.4) que representaba que o es un $\mathcal{A}$ paso o un paso tartamudo con respecto a $f$. Se procede a incluir notación particular sobre esta última definición como sigue:

\begin{align}
[\mathcal{A}]_{\langle x,y \rangle} &\equiv \mathcal{A} \lor (\langle x,y \rangle ' = \langle x,y \rangle) \\ \nonumber
&\equiv \mathcal{A} \lor ((x' = x) \land (y' = y))
\end{align}

donde $x,y \in Var$ y $\langle x,y \rangle$ es una tupla ordenada. Esta nueva notación permite indicar que los estados involucrados o son un $\mathcal{A}$ paso o son un paso tartamudo, dejando las variables $x,y$ invariantes.

Ahora sí, se entiende por \textbf{TLA} a la lógica temporal cuyas fórmulas elementales son predicados y fórmulas de la forma $\Box[\mathcal{A}]_f$, donde $\mathcal{A}$ es una acción y $f$ es una función de estado.

\subsubsection{Invarianza ante tartamudez}\label{subsubsection:LTAsttutering}
Este concepto, se refiere a la propiedad de una fórmula de mantener su verdad o falsedad incluso cuando se introducen repeticiones de estados (tartamudeos) que no cambian el estado observable del sistema. En otras palabras, una fórmula invariante frente a tartamudeo no se ve afectada por los cambios irrelevantes en la secuencia de estados.

Se denomina $\natural \sigma$ como el comportamiento obtenido de $\sigma = \langle s_0, s_1, \ldots \rangle \in St^\infty$ eliminando los pasos tartamudos. La definición precisa es:

\[
\natural(\sigma) = 
\begin{cases} 
\langle s_0, s_0, s_0, \ldots \rangle & \text{si } \forall n \in \mathbb{N},\ s_n = s_0 \\
\natural(\langle s_{1}, s_2, s_3, \ldots \rangle) & \text{si } s_1 = s_0 \\
\langle s_0 \rangle \circ \natural(\langle s_{1}, s_2, s_3, \ldots \rangle) & \text{en otro caso}
\end{cases}
\]

donde $\circ$ denota ``composición'' de comportamientos. A continuación, se enuncia uno de los resultados más importantes de la Lógica Temporal de Acciones:
\begin{proposicion}
    Las fórmulas de la Lógica Temporal de Acciones son invariantes ante tartamudez. Formalmente: $\natural \sigma = \natural \tau$ implica que $\sigma[[F]] = \tau[[F]]$ para toda fórmula $F$ de la TLA y para cualquier $\sigma,\tau \in St^\infty$.
\end{proposicion}

\subsubsection{Cuantificación sobre variables flexibles}
En esta sección se aborda la definición de la cuantificación existencial $\exists x: F$ en el contexto de variables flexibles y fórmulas temporales. La veracidad de $F$ no depende específicamente de los valores actuales de $x$, sino de la existencia de ciertos valores que $x$ puede tomar, haciendo que $F$ sea verdadera. Este enfoque permite una comprensión más profunda de la interacción entre variables cuyos valores son susceptibles de cambio y las fórmulas que se desarrollan en un marco temporal.

Para definir el significado de $\exists x : F$ formalmente, es necesario incluir definiciones auxiliares. Para cualquier variable $x \in Var$ y estados $s,t \in St$, se define $s =_x t$ y significa que $s$ y $t$ assignan los mismos valores a todas las variables distintas de $x$. Esto es:

\begin{align}
s =_x t \triangleq \forall 'v' \neq 'x' : s[[v]] = t[[v]]
\end{align}

y se extiende esta definición a comportamientos $\sigma,\tau \in St^\infty$, con $\sigma = \langle s_0, s_1, \ldots \rangle$ y $\tau = \langle t_0, t_1, \ldots \rangle$ ,de una manera natural:

\begin{align}
\sigma =_x \tau \triangleq \forall n \in Nat : s_n =_x t_n
\end{align}

\noindent
Finalmente, se puede definir el significado de $\exists x : F$ como:

\begin{align}
\sigma[[\exists x : F]] \triangleq \exists \rho, \tau \in St^\infty : (\natural \sigma = \natural \rho) \land (\rho =_x \tau) \land \tau[[F]]
\end{align}

donde $\natural$ es la operación para eliminar pasos tartamudos definida en ~\ref{subsubsection:LTAsttutering}. En el marco de la TLA, el operador de cuantificación existencial $\exists x$ adquiere una interpretación única y ampliada en comparación con su uso en la lógica clásica. Mientras que en la lógica estándar, $\exists x$ denota la existencia de un único valor que puede ser sustituido por $x$, en esta lógica, este operador se extiende para afirmar la existencia no solo de un valor singular, sino de una secuencia infinita de valores para $x$. Esta peculiaridad refleja la naturaleza dinámica y temporal de las variables en la lógica, donde $x$ puede representar diferentes valores en distintos momentos o estados a lo largo del tiempo. A pesar de esta ampliación en su significado, el operador $\exists x$ en TLA sigue obedeciendo las leyes ordinarias de la cuantificación existencial. Esta continuidad garantiza que, aunque se aplique a un conjunto más rico de situaciones, el operador mantiene su coherencia lógica y su integridad.

\subsection{TLA: Sintaxis}\label{subsection:TLASyntax}
En esta sección, se procede a consolidar y resumir la sintaxis de la Lógica Temporal de Acciones (TLA), integrando y sintetizando los elementos ya introducidos a lo largo de la discusión previa. Este apartado sirve como una revisión estructurada y formal de los aspectos sintácticos de TLA, proporcionando una visión cohesiva y comprensiva de su marco lingüístico.

La finalidad de esta recapitulación es asegurar una comprensión clara y completa de la estructura sintáctica de TLA, enfatizando cómo los diferentes componentes se entrelazan para formar un lenguaje lógico coherente y funcional. Se revisarán los símbolos básicos, las reglas de formación y la organización general de la sintaxis, reafirmando su papel en la formulación de expresiones lógicas dentro del contexto de TLA.

\subsubsection{Operadores primarios de la lógica}
\noindent
Los operadores primarios utilizados para la TLA son los siguientes:
\vspace{0.2cm}
\newline
\begin{tabular}{ll}
  $\neg$ : negación & $\land$ : conjunción \\
  $\exists$ : cuantificador existe & $\Box$ : siempre\\
\end{tabular}

\subsubsection{Operadores derivados de la lógica}
\noindent
Los operadores derivados son aquellos que se pueden expresar en términos de los primarios, y son los siguientes:
\vspace{0.2cm}
\newline
\begin{tabular}{ll}
  $\lor$ : disyunción & $\implies$ : implicación \\
  $\Diamond$ : eventualmente & $\leadsto$ : conduce a\\
\end{tabular}

\subsubsection{Conjuntos}
\noindent
Algunos de los conjuntos importantes definidos son:
\vspace{0.2cm}
\newline
\begin{tabular}{ll}
  $Val$ : valores & $Var$ : variables \\
  $St$ : estados & $St^\infty$ : comportamientos \\
  $Act$ : acciones & $Form$ : fórmulas \\
\end{tabular}

\subsubsection{Convención de nombres}
\noindent
Para hacer una notación más integral, aquí se define una convención de nombres para cada objeto sintáctico:
\vspace{0.2cm}
\newline
\begin{tabular}{ll}
  $\langle \text{función de estado} \rangle$ : $f$, $g$, $h$, etc. & $\langle \text{estados} \rangle$ : $s$,$t$,$r$,$s_0$,$s_1$,$s_2$, etc. \\
  $\langle \text{comportamiento} \rangle$ : $\sigma$, $\tau$, $\rho$, etc. & $\langle \text{variable rígida} \rangle$ : $c$, $d$, etc.\\
  $\langle \text{acción} \rangle$ : $\mathcal{A}$, $\mathcal{B}$, $\mathcal{M}$, $\mathcal{N}$, etc. & $\langle \text{fórmula} \rangle$ : $F$, $G$, $H_c$, $H_d$ etc.\\
  $\langle \text{predicado} \rangle$ : $P$, $Q$, $I$, etc. \\
\end{tabular}

\subsubsection{Notación adicional}
\noindent
Alguna notación adicional para ciertos objetos:
\vspace{0.2cm}
\newline
\begin{tabular}{ll}
  $f' \triangleq f(\forall 'v' : v' / v)$ & $[\mathcal{A}]_f \triangleq \mathcal{A} \lor (f' = f)$ \\ 
  $\langle A \rangle_f \triangleq \mathcal{A} \land (f' \neq f)$ & \textit{Unchanged} $f \triangleq f' = f$\\
  $F \lor G \triangleq \neg(\neg F \land G)$ & $F \implies G \triangleq \neg(F \land \neg G)$\\
  $\Diamond F \triangleq \neg \Box \neg F$ & $F \leadsto G \triangleq \Box(F \implies \Diamond G)$\\
  $\text{WF}_f(\mathcal{A}) \triangleq (\Box\Diamond \langle \mathcal{A}\rangle_f) \lor (\Box\Diamond \neg \textit{Enabled} \hspace{0.1cm} \langle \mathcal{A}\rangle_f)$ & $\text{SF}_f(\mathcal{A}) \triangleq (\Box\Diamond \langle \mathcal{A}\rangle_f) \lor (\Diamond\Box \neg \textit{Enabled} \hspace{0.1cm} \langle \mathcal{A}\rangle_f)$  \\
\end{tabular}

\subsubsection{Sintaxis}
\noindent
A continuación, se escriben las reglas para la construcción de los objetos lógicos:

\begin{align*}
    \langle \text{fórmula} \rangle &\triangleq \langle \text{predicado} \rangle \hspace{0.2cm} | \hspace{0.2cm} \langle \Box [\langle \text{acción} \rangle]_{\langle \text{función de estado} \rangle} \rangle \\
    &| \hspace{0.2cm} \neg \langle \text{fórmula} \rangle \hspace{0.2cm} | \hspace{0.2cm} \langle \text{fórmula} \rangle \land \langle \text{fórmula} \rangle \\
    &| \hspace{0.2cm} \Box \langle \text{fórmula} \rangle \hspace{0.2cm} | \hspace{0.2cm} \exists \langle \text{var. rígida} \rangle : \langle \text{fórmula} \rangle
\end{align*}

\begin{align*}
    \langle \text{acción} \rangle &\triangleq \text{expresión con constantes, variables, y variables con prima}
\end{align*}

\begin{align*}
    \langle \text{predicado} \rangle &\triangleq \text{función de estado} \hspace{0.2cm} | \hspace{0.2cm} \textit{Enabled} \hspace{0.2cm} \langle \text{acción} \rangle
\end{align*}

\begin{align*}
    \langle \text{función de estado} \rangle &\triangleq \text{expresión con constantes y variables}
\end{align*}

\subsection{TLA: Semántica}\label{subsection:TLASemantic}
En la presente sección, se aborda de forma resumida la semántica de la Lógica Temporal de Acciones (TLA), integrando los principios y conceptos previamente explorados para ofrecer una visión general del significado y la interpretación en TLA.

\subsubsection{Interpretaciones semánticas}
\begin{tabular}{ll}
    $s[[f]] \triangleq f(\forall 'v' : s[[v]] / v)$ & $s[[\mathcal{A}]]t \triangleq \mathcal{A}(\forall 'v' : s[[v]] / v, t[[v]] / v')$\\
    $\sigma[[F \land G]] \triangleq \sigma[[F]] \land \sigma[[G]]$ & $\sigma[[\neg F]] = \neg \sigma [[F]]$\\
    $\sigma[[F \implies G]] \triangleq \sigma[[F]] \implies \sigma[[G]]$ & $\sigma[[F \lor G]] \triangleq \sigma[[F]] \lor \sigma[[G]]$\\
    $\sigma[[\exists c : F]] : \exists c \in Val : \sigma[[F]]$ &\\  
\end{tabular}

\vspace{0.2cm}
\begin{tabular}{ll}
    $\models \mathcal{A} \triangleq \forall s,t \in St : \hspace{0.2cm} \models s[[\mathcal{A}]]t$ & $\models F \triangleq \forall \sigma \in St^\infty : \hspace{0.2cm} \models \sigma[[F]]$\\
\end{tabular}

\vspace{0.2cm}
\begin{tabular}{l}
    $s[[\textit{Enabled} \hspace{0.2cm} \mathcal{A}]] \triangleq \exists t \in St : s[[\mathcal{A}]]t$ \\
    $\langle s_0, s_1, \ldots\rangle[[\Box F]] \triangleq \forall n \in Nat : \langle s_n, s_{n+1}, \ldots\rangle[[F]]$ \\
    $\langle s_0, s_1, \ldots\rangle[[\mathcal{A}]] \triangleq s_0[[\mathcal{A}]]s_1$\\
\end{tabular}

\subsection{TLA: Reglas de prueba}
Las reglas de la Lógica Temporal de Acciones son usadas para derivar tautologías temporales La regla STL1-STL6, la Regla de Celosía (Lattice Rule) y las reglas básicas TLA1 y TLA2 constituyen un sistema axiomático independiente para hacer razonamientos, sólido en términos de su semántica. Un sistema es \textit{sólido} si todas las conclusiones que se pueden derivar de él son verdaderas en todos los modelos o interpretaciones que satisfacen sus axiomas. En otras palabras, la solidez garantiza que el sistema no conduce a conclusiones falsas si se parte de premisas verdaderas.

\subsubsection{La primera regla: STL1}
La primera regla, STL1, significa ue $F$ es una tautología proposicional o es derivable por las leyes de la lógica proposicional a partir de fórmulas probables.

\subsubsection{Regla de Celosía (Lattice Rule)}
Esta regla se aplica a un conjunto $S$, que puede ser infinito, y a una función que asocia cada elemento $c$ de $S$ con una fórmula específica $H_c$. Se define un orden parcial $\succ$ sobre $S$ que se considera bien establecido si existe, y solo si hay una secuencia finita descendente tal que $c_0 \succ c_1 \succ \ldots$, con cada $c_i$ perteneciente a $S$ para todo $i \in Nat$. El propósito de la Regla de Celosía es proporcionar una base formal para los argumentos de cuenta regresiva, que son comúnmente empleados en la demostración de la terminación de programas secuenciales.

\subsubsection{Axiomas}
\begin{tabular}{ll}
    \textbf{STL1} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
        \frac{\text{F provable mediante l.prop.}}{\Box F}
    \end{equation*}
    \end{minipage} \\[10pt]
    \textbf{STL2} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
        \vdash \Box F \implies F
    \end{equation*}
    \end{minipage} \\[10pt]
    \textbf{STL3} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
        \vdash \Box\Box F \equiv \Box F
    \end{equation*}
    \end{minipage} \\[10pt]
    \textbf{STL4} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
        \frac{F \implies G}{\Box F \implies \Box G}
    \end{equation*}
    \end{minipage} \\[15pt]
    \textbf{STL5} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
        \vdash \Box(F \land G) \equiv (\Box F) \land (\Box G)
    \end{equation*}
    \end{minipage} \\[5pt]
    \textbf{STL6} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
        \vdash (\Diamond\Box F) \land (\Diamond\Box G) \equiv \Diamond\Box(F \land G)
    \end{equation*}
    \end{minipage}
\end{tabular}

\vspace{0.5cm}

\begin{tabular}{ll}
    \textbf{Celosía.}
    &  $\succ$ orden parcial bien definido sobre $S \neq \emptyset$ \\
    & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
        \frac{F \land (c \in S) \implies (H_c \leadsto (G \lor \exists d \in S : (c \succ d) \land H_d))}{F \implies ((\exists c \in S : H_c) \leadsto G)}
    \end{equation*}
    \end{minipage} \\
\end{tabular}

\subsubsection{Reglas de cuantificación}
\begin{tabular}{ll}
    \textbf{F1} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
        \vdash F(e/c) \implies \exists c : F
    \end{equation*}
    \end{minipage} \\[10pt]
    \textbf{F2} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
    \begin{array}{l}
        F \implies G \\
        \text{c no ocurre libre en} \hspace{0.2cm} G \\
        \hline
        (\exists c : F) \implies G
    \end{array}
    \end{equation*}
    \end{minipage}
\end{tabular}

\subsubsection{Reglas básicas de TLA}
\begin{tabular}{ll}
    \textbf{TLA1} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
        \vdash \Box P \equiv P \land \Box[P \implies P']_P
    \end{equation*}
    \end{minipage} \\[10pt]
    \textbf{TLA2} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
    \begin{array}{c}
        P \land [\mathcal{A}]_f \implies Q \land \mathcal{B}_g \\
        \hline
        \Box P \land \Box [\mathcal{A}]_f \implies \Box Q \land \Box[\mathcal{B}]_g
    \end{array}
    \end{equation*}
    \end{minipage}
\end{tabular}

\subsubsection{Reglas adicionales}
\begin{tabular}{ll}
    \textbf{INV1} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
    \begin{array}{c}
        I \land [\mathcal{N}]_f \implies I' \\
        \hline
        I \land \Box [\mathcal{N}]_f \implies \Box I
    \end{array}
    \end{equation*}
    \end{minipage} \\[10pt]
    \textbf{INV2} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
    \begin{array}{c}
        \vdash \Box I \implies (\Box[\mathcal{N}]_f \equiv \Box [\mathcal{N} \land I \land I']_f)
    \end{array}
    \end{equation*}
    \end{minipage}
\end{tabular}

\vspace{0.25cm}
\begin{tabular}{ll}
    \textbf{WF1} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
    \begin{array}{l}
        P \land [\mathcal{N}]_f \implies (P' \lor Q') \\
        P \land \langle \mathcal{N} \land \mathcal{A} \rangle_f \implies Q' \\
        P \implies \textit{Enabled} \hspace{0.2cm} \langle A \rangle_f \\
        \hline
        \Box[\mathcal{N}]_f \land WF_f(\mathcal{A}) \implies (P \leadsto Q)
    \end{array}
    \end{equation*}
    \end{minipage} \\[10pt]
    \textbf{WF2} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
    \begin{array}{l}
        \langle \mathcal{N} \land \mathcal{B} \rangle_f \implies \langle \mathcal{M} \rangle_g \\
        P \land P' \land \langle \mathcal{N} \land \mathcal{A} \rangle_f \implies \mathcal{B} \\
        P \land \textit{Enabled} \hspace{0.2cm} \langle \mathcal{M} \rangle_g \implies \textit{Enabled} \hspace{0.2cm} \langle \mathcal{A} \rangle_f \\
        \Box [\mathcal{N} \land \mathcal{B}]_f \land WF_f(\mathcal{A}) \land \Box F \implies \Diamond \Box P \\
        \hline
        \Box[\mathcal{N}]_f \land WF_f(\mathcal{A}) \land \Box F \implies WF_g(\mathcal{M})
    \end{array}
    \end{equation*}
    \end{minipage}
\end{tabular}

\vspace{0.25cm}
\begin{tabular}{ll}
    \textbf{SF1} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
    \begin{array}{l}
        P \land [\mathcal{N}]_f \implies (P' \lor Q') \\
        P \land \langle \mathcal{N} \land \mathcal{A} \rangle_f \implies Q' \\
        \Box P \land \Box [\mathcal{N}]_f \land \Box F \implies \Diamond \hspace{0.2cm} \textit{Enabled} \hspace{0.2cm} \langle \mathcal{A} \rangle_f \\
        \hline
        \Box[\mathcal{N}]_f \land SF_f(\mathcal{A}) \land \Box F \implies (P \leadsto Q)
    \end{array}
    \end{equation*}
    \end{minipage} \\[10pt]
    \textbf{SF2} & 
    \begin{minipage}{0.5\linewidth}
    \begin{equation*}
    \begin{array}{l}
        \langle \mathcal{N} \land \mathcal{B} \rangle_f \implies \langle \mathcal{M} \rangle_g \\
        P \land P' \land \langle \mathcal{N} \land \mathcal{A} \rangle_f \implies \mathcal{B} \\
        P \land \textit{Enabled} \hspace{0.2cm} \langle \mathcal{M} \rangle_g \implies \textit{Enabled} \hspace{0.2cm} \langle \mathcal{A} \rangle_f \\
        \Box [\mathcal{N} \land \mathcal{B}]_f \land SF_f(\mathcal{A}) \land \Box F \implies \Diamond \Box P \\
        \hline
        \Box[\mathcal{N}]_f \land SF_f(\mathcal{A}) \land \Box F \implies SF_g(\mathcal{M})
    \end{array}
    \end{equation*}
    \end{minipage}
\end{tabular}

\newpage
El principio de inducción establecido por la regla TLA1 facilita la demostración de la fórmula $\Box P$. Esta regla subraya la idea elemental de que un predicado $P$ permanece cierto en todo momento si inicialmente es verdadero y si en cada etapa subsiguiente, partiendo de una situación donde $P$ es verdadero, este continúa siendo verdadero. Mientras tanto, la validez de TLA2 es inmediata a partir de STL4 y STL5.

La regla INV1 se aplica para confirmar que un programa cumple con una propiedad invariante denotada como $\Box I$. La premisa de esta regla establece que un paso dado por $[\mathcal{N}]_f$ no puede invalidar a $I$. De esto se deduce que si $I$ es verdadero al inicio y cada acción subsiguiente es un paso $[\mathcal{N}]_f$, entonces $I$ se mantiene verdadero de manera constante.

La regla WF1 se utiliza para deducir la propiedad $P \leadsto Q$ a partir de una condición de justicia débil $WF_f(\mathcal{A})$. Por otra parte, la regla WF2 es utilizada pra deducir una condición de justicia débil a partir de otra. Las reglas SF1 y SF2 son análogas a WF1 y WF2, pero para justicia fuerte.

\section{Un ejemplo sencillo de verificación usando TLA}\label{section:TLAexample}
Tras haber explorado los fundamentos teóricos y las características distintivas de la Lógica Temporal de Acciones (TLA), esta sección se dedica a ilustrar cómo se aplica TLA en un contexto práctico. A través de un ejemplo sencillo de verificación, se demostrará el proceso paso a paso para verificar las propiedades de un programa o sistema concurrente utilizando las herramientas y conceptos de TLA.

El siguiente ejemplo denota un simple programa que cuando se ejecuta, permanece incrementando las dos únicas variables $x,y$ inicializadas a 0, eligiendo de forma no determinística cuál incrementar.

\begin{figure}[ht]
\centering
\begin{lstlisting}[basicstyle=\ttfamily\small, frame=single]
    var natural x,y = 0;
    do 
       < true -> x := x + 1 >
       [ ]
       < true -> y := y + 1 >
    od
\end{lstlisting}
\caption{Ejemplo de programa para especificación: Incremento.}
\label{fig:TLAincrement}
\end{figure}

Se procede a ir especificando poco a poco el programa de incremento. Se denotara por $\Phi$ a la fórmula que especifica el programa por completo. En primer lugar, se puede ver que las variables $x,y \in Var$, están inicializadas a $0$, por lo que en el estado inicial del programa se tendrá que $x = 0$, $y = 0$. Esto se puede representar por el predicado $Init_{\Phi}$, que por definición será:

\begin{align*}
    Init_{\Phi} \triangleq (x = 0) \land (y = 0)
\end{align*}

A continuación, como se ha mencionado en la descripción del programa, se elige de forma no determinista cuál de las dos variables incrementar. Esto se puede representar considerando dos acciones, llamémosles $\mathcal{A}_1$ y $\mathcal{A}_2$ que por definición indican:

\begin{align*}
    \mathcal{A}_1 &\triangleq (x' = x + 1) \land (y' = y) \\
    \mathcal{A}_2 &\triangleq (x' = x) \land (y' = y + 1)
\end{align*}

Estos son los únicos dos posibles pasos, que se pueden formular de forma conjunta considerando $\mathcal{A}$ como:

\begin{align*}
    \mathcal{A} \triangleq \mathcal{A}_1 \lor \mathcal{A}_2
\end{align*}

Con esta información, y teniendo en cuenta la notación definida en (5.21), ya se puede especificar el programa con una fórmula TLA:

\begin{align}
    \Phi \triangleq Init_{\Phi} \land \Box [\mathcal{A}]_{\langle x,y \rangle}
\end{align}

Está claro que para que $\Phi$ sea cierta tiene que darse que primero, el estado de inicialización se cumpla (siempre es verdad), y segundo, $\Box [\mathcal{A}]_{\langle x,y \rangle}$, que asegura que todo paso es un $\mathcal{A}$ paso o un paso que deja a las variables sin modificar. Aunque viendo el programa la condición de cambio de una de las dos variables \textit{parece} claro que se hará, el motivo de definirlo así es para ajustarse a las reglas para escribir fórmulas TLA sintácticamente correctas como se indicó en el apartado de sintaxis en ~\ref{subsection:TLASyntax}.

De hecho, la fórmula $\Phi$ tal y como está escrita ahora mismo, es una \textit{propiedad de seguridad}, pues nunca nada malo va a suceder. Lo que queda por hacer es añadir la propiedad de vivacidad para asegurar que el programa se mantiene ejecutándose. Volviendo a tener en cuenta la notación introducida, se considera la forma dual $\langle \mathcal{A} \rangle_{\langle x,y \rangle}$:

\begin{align*}
    \langle \mathcal{A} \rangle_{\langle x,y \rangle} &\triangleq \langle \mathcal{A}_1 \rangle_{\langle x,y \rangle} \lor \langle \mathcal{A}_2 \rangle_{\langle x,y \rangle} \\
    &\triangleq \mathcal{A}_1 \land ((x' \neq x) \land (y' \neq y)) \lor \mathcal{A}_2 \land ((x' \neq x) \land (y' \neq y))
\end{align*}

\noindent
y teniendo en cuenta que $\neg \mathcal{A} \equiv \neg \mathcal{A}_1 \land \neg \mathcal{A}_2$ y que $\neg \Box[\neg \mathcal{A}]_f \equiv \Diamond \langle \mathcal{A} \rangle_f$, $\Phi$ queda:

\begin{align}
    \Phi &\triangleq Init_{\Phi} \land \Box [\mathcal{A}]_{\langle x,y \rangle} \land \Box(\Diamond \langle \mathcal{A}_1 \rangle_{\langle x,y \rangle} \land \Diamond \langle \mathcal{A}_2 \rangle_{\langle x,y \rangle} )\\ \nonumber
    &\triangleq Init_{\Phi} \land \Box [\mathcal{A}]_{\langle x,y \rangle} \land \Box\Diamond \langle \mathcal{A}_1 \rangle_{\langle x,y \rangle} \land \Box\Diamond \langle \mathcal{A}_2 \rangle_{\langle x,y \rangle}
\end{align}

Para aumentar la precisión de la especificación, es más conveniente expresar los términos de vivacidad en términos de justicia (recordando que la justicia es un tipo particular de propiedad de vivacidad). Se reescribirá la última adición realizada en 5.26 para especificar la propiedad de vivacidad que se había comentado que era la de probar que el programa nunca termina. Por ello, se considera ahora el predicado \textit{Enabled} $\langle \mathcal{A}_1 \rangle_{\langle x,y \rangle}$, que es cierta para cualquier tipo de comportamiento $\sigma \in St$ considerado, porque  siempre existe un paso que incrementa en uno la variable $x$ dejando $y$ sin cambios. Como $\Box\neg \top \equiv \bot$, y recordando las definiciones de justicia débil y fuerte, $WF_{\langle x,y \rangle}(\mathcal{A}_1) \equiv \Box\Diamond\langle \mathcal{A}_1\rangle_{\langle x,y\rangle}$ al igual que $SF_{\langle x,y\rangle}(\mathcal{A}_1) \equiv \Box\Diamond\langle \mathcal{A}_1\rangle_{\langle x,y\rangle}$. Un razonamiento análogo se puede realizar para $\Box\Diamond\langle \mathcal{A}_2 \rangle_{\langle x,y \rangle}$.

Como se quería probar que el programa no terminaba, y eso es una condición débil de vivacidad, el programa queda totalmente especificado finalmente por la fórmula:

\begin{align}
    \Phi \triangleq Init_{\Phi} \land \Box [\mathcal{A}]_{\langle x,y \rangle} \land WF_{\langle x,y \rangle}(\mathcal{A}_1) \land WF_{\langle x,y \rangle}(\mathcal{A}_2)
\end{align}

Hay otras propiedades que se pueden demostrar utilizando la Lógica Temporal de Acciones, como por ejemplo, la invarianza del predicado $P$ que se enuncia como sigue:

\begin{align}
    P &\triangleq \text{``x e y son números naturales''} \\
    &\triangleq (x \in Nat) \land (y \in Nat)
\end{align}

\noindent
Esta corrección sobre el programa se puede expresar formalmente como:

\begin{align}
    \Phi \implies \Box P
\end{align}. 

\noindent
La regla INV1 dice que hay que probar:
\begin{align}
    Init_{\Phi} &\implies P \\
    P \land [\mathcal{A}]_{\langle x,y \rangle} &\implies P'
\end{align}

\noindent
La prueba de (5.31) es trivial pues en efecto:

\begin{align*}
    Init_{\Phi} &\triangleq (x = 0) \land (y = 0) \\
    &\implies (x \in Nat) \land (y \in Nat) \\
    &\implies P
\end{align*}
 
La prueba de (5.32) también es sencilla, realizando una descomposición en primer lugar de $[\mathcal{A}]_{\langle x,y \rangle}$:
\begin{equation*}
\begin{array}{rlr}
    [\mathcal{A}]_{\langle x,y \rangle} &\equiv \mathcal{A} \lor (\langle x,y \rangle' = \langle x,y \rangle) & \quad \text{por (5.21)}\\
    &\equiv \mathcal{A}_1 \lor \mathcal{A}_2 \lor (\langle x,y \rangle' = \langle x,y \rangle) & \quad \text{por definición de $ \mathcal{A}$}
\end{array}
\end{equation*}

Ahora faltaría probar cada caso por separado, al ser una disyunción de casos queda:
\begin{align}
    P \land \mathcal{A}_1 \implies P'\\
    P \land \mathcal{A}_2 \implies P'\\
    P \land (\langle x,y \rangle' = \langle x,y \rangle) \implies P'
\end{align}

Se opta por probar uno de los casos, siendo los otros dos totalmente equivalentes. Se decide demostrar (5.34). Primero, se entiende por $P'$ como:

\begin{align}
    P' \equiv (x' \in Nat) \land (y' \in Nat)
\end{align}

\noindent
Por lo que probar (5.34) resulta en probar la veracidad de:
\begin{align}
    P' \land \mathcal{A}_2 \implies x' \in Nat \\
    P' \land \mathcal{A}_2 \implies y' \in Nat
\end{align}

\noindent
Y en el caso de (5.38) (análogo con (5.37)):
\begin{equation*}
\begin{array}{rlr}
    P' \land \mathcal{A}_2 &\implies (y \in Nat) \land (y' = y + 1) & \quad \text{por definición de $P$ y $\mathcal{A}_2$}\\
    &\implies (y' \in Nat) & \quad \text{propiedades de $\mathbb{N}$}
\end{array}
\end{equation*}

Finalmente, tras haber demostrado las condiciones requeridas, ahora se puede deducir (5.30):
\begin{equation*}
\begin{array}{rlr}
    \Phi &\implies Init_{\Phi} \land \Box[\mathcal{A}]_{\langle x,y \rangle} & \quad \text{por definición de $\Phi$}\\
    &\implies P \land \Box[\mathcal{A}]_{\langle x,y \rangle} & \quad \text{por (5.31)}\\
    &\implies \Box P & \quad \text{por (5.32) y INV1}
\end{array}
\end{equation*}

\noindent
En conclusión, queda demostrado que $\Phi$ siempre satisface la propiedad $P$.