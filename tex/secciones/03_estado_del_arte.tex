\chapter{\textbf{Estado del arte}}
La \textit{programación concurrente} sienta sus bases en la década de los 1960 con la aparición de los sistemas operativos multiprogramación, que pretendían resolver uno de los problemas más críticos que se daban en aquella época: el uso eficiente de los recursos hardware. Anteriormente, la CPU ejecutaba sólo un programa a la vez, quedando inactiva si se producían operaciones de entrada/salida subutilizando sus recursos, produciendo como resultado un rendimiento deficiente. Con la multiprogramación, varios programas podían residir simultáneamente en la memoria principal, permitiendo a la CPU ejecutar otro programa diferente mientras se gestionaba una interrupción de E/S. Esta gestión se facilitó gracias a la invención de los ``canales'', controladores de dispositivos que operaban de forma independiente. Esta revolucionaria técnica tuvo un gran impacto en algunos sistemas informáticos que se desarrollaban por aquel entonces, como es el caso de los ``mainframes'' \cite{TecnologiaInformaticaMainframe}.


La programación concurrente fue inicialmente motivo de preocupación de los diseñadores de sistemas operativos. Al final de esta década de 1960, los diseñadores de hardware desarrollaron máquinas multiprocesador, que supusieron todo un reto para la implementación de nuevos sistemas operativos adaptados a estos recursos, pero también definió una nueva oportunidad para que los desarrolladores de aplicaciones pudieran emerger y posicionarse en el mercado laboral como una profesión con grandes expectativas a futuro.



El primer gran reto de esta nueva técnica de programación fue resolver lo que se denomina como: \textit{el problema de la sección crítica} \cite{GeeksForGeeksCriticalSection}. Este desafío central se refiere al desarrollo de algoritmos efectivos para la sincronización de procesos concurrentes que requieren acceder a un recurso compartido. La importancia de resolver este problema radica en la necesidad de evitar conflictos y garantizar la coherencia de los datos cuando múltiples procesos intentan leer o modificar el mismo recurso simultáneamente. La correcta gestión de la sección crítica es crucial para asegurar que los sistemas concurrentes funcionen de manera fiable y eficiente. Para entender mejor y modelar este reto, se plantearon problemas teóricos como \textit{la cena de los filósofos} \cite{brosgol1996dining}, \textit{lectores y escritores} \cite{nithyasrikannathalreaders}, \textit{el barbero durmiente} \cite{SariSleepingBarber} o el \textit{problema de los fumadores} \cite{MTUSmokerProblem}.


Estos escenarios anteriormente mencionados han sido ampliamente estudiados, generando miles de artículos que proponen soluciones, mejoras, debates y nuevas implementaciones de primitivas de sincronización como los semáforos o los monitores, que simplificaban la tarea del programador. Paralelamente, los lenguajes de programación de alto nivel estaban proliferando y evolucionando. Un ejemplo notable es Simula \cite{Sklenar1997OOPSimula}, desarrollado en la década de 1960 por Ole-Johan Dahl y Kristen Nygaard. Considerado uno de los primeros lenguajes orientados a objetos, Simula también introdujo conceptos fundamentales que influirían en la simulación de concurrencia, aunque su principal aporte fue establecer las bases para la programación orientada a objetos, un paradigma que tendría un impacto significativo en el desarrollo futuro de lenguajes y técnicas de programación concurrente.


Al final de la década de 1970 y principios de 1980, el surgimiento de redes de ordenadores como ARPANET, que facilitó la computación en áreas amplias, y el desarrollo de tecnologías como Ethernet para redes locales, marcó el comienzo de una nueva era en la informática. Estos avances no solo transformaron la forma en que las computadoras se conectaban y comunicaban entre sí, sino que también ampliaron significativamente el campo de la programación concurrente. Mientras la programación concurrente se enfoca en gestionar múltiples procesos dentro de un mismo sistema, las redes de computadoras introdujeron el desafío de coordinar procesos que se ejecutan en diferentes máquinas físicas. Esto dio origen a lo que se conoce como \textit{programación distribuida}, un enfoque que extendía los principios de la programación concurrente a sistemas distribuidos cuya esencia reside en que los procesos interactúan entre ellos a través del envío de mensajes en vez de escribir y leer variables compartidas.


A medida que la programación concurrente y distribuida ganaban relevancia en la década de 1980 y 1990, su integración en los lenguajes de programación de alto nivel comenzó a materializarse de manera significativa. Un hito notable en este desarrollo fue el lenguaje de programación Ada \cite{burns1998concurrency}, introducido en 1983. Diseñado originalmente para satisfacer las exigentes necesidades de los proyectos de defensa y sistemas en tiempo real, Ada se destacó por su soporte nativo para la programación concurrente. Su enfoque en la seguridad, la fiabilidad y la gestión sofisticada de tareas concurrentes lo convirtió en una herramienta fundamental para aplicaciones críticas. Posteriormente, en la década de 1990, Java emergió como un lenguaje de programación influyente, llevando la programación concurrente a un público más amplio. Con su API de concurrencia, Java simplificó la gestión de hilos y procesos concurrentes, haciendo que la programación de este tipo fuera más accesible y manejable para los desarrolladores. Esta API proporcionó un conjunto robusto de herramientas y estructuras para el manejo eficiente de tareas concurrentes y sistemas distribuidos, reflejando la creciente demanda de aplicaciones que operaban en entornos de red y web. La evolución de la programación concurrente en Ada y Java no solo demuestra cómo se han adaptado los lenguajes de programación a desafíos técnicos complejos, sino también cómo han evolucionado para satisfacer las necesidades de aplicaciones modernas en diversos entornos de computación. Pero no solo los lenguajes en sí, sino también las herramientas para crearlos, evolucionaron significativamente durante este periodo. El desarrollo de herramientas avanzadas para generar compiladores facilitó la creación de lenguajes de programación más sofisticados, especialmente aquellos diseñados para la programación concurrente y distribuida. Estas herramientas permitieron a los diseñadores de lenguajes experimentar con nuevas construcciones y paradigmas, facilitando el desarrollo de lenguajes que pudieran manejar de manera más eficiente y segura las complejidades inherentes a la concurrencia y la distribución. 


Sin embargo, cada vez que se implementaban mejoras en la programación concurrente y distribuida, con nuevas ideas y hardware, la complejidad de los programas aumentaba exponencialmente. Esto llevó a un incremento similar en la dificultad de verificar su funcionamiento correcto. Poco después del origen de este modelo de programación, surgió la necesidad de introducir formalismos capaces de demostrar rigurosamente que un programa concurrente posee ciertas propiedades. En este contexto, las herramientas matemáticas formales, especialmente la lógica temporal, se convirtieron en indispensables. La lógica temporal, que se ocupa de los aspectos temporales del razonamiento en la lógica matemática, permitía especificar y razonar sobre el comportamiento de los programas a lo largo del tiempo, asegurando propiedades como la seguridad (nunca ocurrirá nada malo) y la vivacidad (realmente sucede algo bueno) en sistemas concurrentes.


Un desarrollo particularmente significativo en el campo de la verificación de sistemas fue la Lógica Temporal de Acciones (TLA) de Leslie Lamport, cuya vida y carrera han sido tan influyentes como sus logros académicos \footnote{Lamport fue también el desarrollador inicial de \LaTeX, el sistema de composición de documentos utilizado para redactar este informe. A lo largo de su carrera, ha sido galardonado con numerosos premios, incluyendo el prestigioso Premio Turing, por sus contribuciones a la informática teórica. Sus trabajos, incluyendo la TLA, han influenciado tanto la teoría como la práctica en el diseño y verificación de sistemas distribuidos y concurrentes.}. Nacido en 1941 en Nueva York, Lamport demostró un interés temprano en las matemáticas y la ciencia, lo que eventualmente lo llevó a obtener un Ph.D. en Matemáticas. Su transición hacia la computación fue motivada por un interés creciente en los problemas de sistemas distribuidos y la sincronización de procesos, un campo en el que se convertiría en un líder mundial.


Lamport, una figura destacada en la computación teórica, ha sido pionero en proponer metodologías rigurosas para el diseño y análisis de algoritmos en entornos complejos. La metodología de la TLA, que permite describir el comportamiento de un sistema en términos de estados y transiciones entre estos, facilita la verificación de propiedades críticas de sistemas complejos. Su visión era proporcionar una herramienta que no solo facilitara la especificación precisa de estos sistemas, sino que también permitiera su análisis y verificación de manera sistemática y confiable.


En la actualidad, la programación concurrente y distribuida se ha consolidado como un pilar fundamental en el panorama tecnológico. En el ámbito de la computación ubicua, donde múltiples dispositivos y sensores interactúan en tiempo real, es crucial mantener la precisión y la sincronización para ofrecer experiencias de usuario cohesivas y confiables. En el campo de la inteligencia artificial, la capacidad de manejar operaciones de procesamiento paralelo y distribuido resulta esencial para analizar grandes conjuntos de datos y ejecutar complejos algoritmos de aprendizaje automático. La corrección y eficiencia de los procesos concurrentes son vitales en áreas como el reconocimiento de patrones y el procesamiento de lenguaje natural. En el procesamiento multimedia, esta programación facilita la manipulación eficiente de contenidos de alta definición en tiempo real, siendo la precisión en la sincronización y la integridad de los datos fundamentales en aplicaciones que van desde la edición de vídeo hasta la transmisión en vivo. Estos ejemplos ilustran la omnipresencia y el impacto crucial de la programación concurrente y distribuida en la tecnología moderna, resaltando la necesidad de métodos rigurosos para su verificación fiable, lo que a su vez impulsa la innovación tecnológica.